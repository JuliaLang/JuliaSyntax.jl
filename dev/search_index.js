var documenterSearchIndex = {"docs":
[{"location":"howto/#How-To","page":"How To","title":"How-To","text":"","category":"section"},{"location":"howto/","page":"How To","title":"How To","text":"This section contains brief recipes for particular tasks","category":"page"},{"location":"howto/#Use-JuliaSyntax-as-the-default-parser","page":"How To","title":"Use JuliaSyntax as the default parser","text":"","category":"section"},{"location":"howto/","page":"How To","title":"How To","text":"To use JuliaSyntax as the default Julia parser for the REPL and to include() files, parse code with Meta.parse(), etc, put the following in your startup.jl file:","category":"page"},{"location":"howto/","page":"How To","title":"How To","text":"using JuliaSyntax\nJuliaSyntax.enable_in_core!()","category":"page"},{"location":"howto/","page":"How To","title":"How To","text":"This works well in Julia 1.9 but in Julia 1.8 will cause some startup latency. To reduce that you can create a custom system image by running the code in ./sysimage/compile.jl as a Julia script (or directly using the shell, on unix). Then use julia -J $resulting_sysimage.","category":"page"},{"location":"howto/","page":"How To","title":"How To","text":"Using a custom sysimage has the advantage that package precompilation will also go through the JuliaSyntax parser.","category":"page"},{"location":"howto/#VSCode","page":"How To","title":"VSCode","text":"","category":"section"},{"location":"howto/","page":"How To","title":"How To","text":"To use JuliaSyntax as the default parser for Julia within VSCode, add the following to your startup.jl file:","category":"page"},{"location":"howto/","page":"How To","title":"How To","text":"import JuliaSyntax\nJuliaSyntax.enable_in_core!()","category":"page"},{"location":"howto/","page":"How To","title":"How To","text":"To reduce startup latency you can combine with a custom system as described in the Julia VScode docs, combined with the precompile execution file in sysimage/precompile_exec.jl in the source tree. For additional detail see the discussion in issue #128.","category":"page"},{"location":"api/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api/#Parsing","page":"API Reference","title":"Parsing","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"JuliaSyntax.parsestmt\nJuliaSyntax.parseall\nJuliaSyntax.parseatom","category":"page"},{"location":"api/#JuliaSyntax.parsestmt","page":"API Reference","title":"JuliaSyntax.parsestmt","text":"# Parse a single expression/statement\nparsestmt(TreeType, text, [index];\n          version=VERSION,\n          ignore_trivia=true,\n          filename=nothing,\n          ignore_errors=false,\n          ignore_warnings=ignore_errors)\n\n# Parse all statements at top level (file scope)\nparseall(...)\n\n# Parse a single syntax atom\nparseatom(...)\n\nParse Julia source code string text into a data structure of type TreeType. parsestmt parses a single Julia statement, parseall parses top level statements at file scope and parseatom parses a single Julia identifier or other \"syntax atom\".\n\nIf text is passed without index, all the input text must be consumed and a tree data structure is returned. When an integer byte index is passed, a tuple (tree, next_index) will be returned containing the next index in text to resume parsing. By default whitespace and comments before and after valid code are ignored but you can turn this off by setting ignore_trivia=false.\n\nversion (default VERSION) may be used to set the syntax version to any Julia version >= v\"1.0\". We aim to parse all Julia syntax which has been added after v\"1.0\", emitting an error if it's not compatible with the requested version.\n\nPass filename to set any file name information embedded within the output tree, if applicable. This will also annotate errors and warnings with the source file name.\n\nA ParseError will be thrown if any errors or warnings occurred during parsing. To avoid exceptions due to warnings, use ignore_warnings=true. To also avoid exceptions due to errors, use ignore_errors=true.\n\n\n\n\n\n","category":"function"},{"location":"api/#JuliaSyntax.parseall","page":"API Reference","title":"JuliaSyntax.parseall","text":"# Parse a single expression/statement\nparsestmt(TreeType, text, [index];\n          version=VERSION,\n          ignore_trivia=true,\n          filename=nothing,\n          ignore_errors=false,\n          ignore_warnings=ignore_errors)\n\n# Parse all statements at top level (file scope)\nparseall(...)\n\n# Parse a single syntax atom\nparseatom(...)\n\nParse Julia source code string text into a data structure of type TreeType. parsestmt parses a single Julia statement, parseall parses top level statements at file scope and parseatom parses a single Julia identifier or other \"syntax atom\".\n\nIf text is passed without index, all the input text must be consumed and a tree data structure is returned. When an integer byte index is passed, a tuple (tree, next_index) will be returned containing the next index in text to resume parsing. By default whitespace and comments before and after valid code are ignored but you can turn this off by setting ignore_trivia=false.\n\nversion (default VERSION) may be used to set the syntax version to any Julia version >= v\"1.0\". We aim to parse all Julia syntax which has been added after v\"1.0\", emitting an error if it's not compatible with the requested version.\n\nPass filename to set any file name information embedded within the output tree, if applicable. This will also annotate errors and warnings with the source file name.\n\nA ParseError will be thrown if any errors or warnings occurred during parsing. To avoid exceptions due to warnings, use ignore_warnings=true. To also avoid exceptions due to errors, use ignore_errors=true.\n\n\n\n\n\n","category":"function"},{"location":"api/#JuliaSyntax.parseatom","page":"API Reference","title":"JuliaSyntax.parseatom","text":"# Parse a single expression/statement\nparsestmt(TreeType, text, [index];\n          version=VERSION,\n          ignore_trivia=true,\n          filename=nothing,\n          ignore_errors=false,\n          ignore_warnings=ignore_errors)\n\n# Parse all statements at top level (file scope)\nparseall(...)\n\n# Parse a single syntax atom\nparseatom(...)\n\nParse Julia source code string text into a data structure of type TreeType. parsestmt parses a single Julia statement, parseall parses top level statements at file scope and parseatom parses a single Julia identifier or other \"syntax atom\".\n\nIf text is passed without index, all the input text must be consumed and a tree data structure is returned. When an integer byte index is passed, a tuple (tree, next_index) will be returned containing the next index in text to resume parsing. By default whitespace and comments before and after valid code are ignored but you can turn this off by setting ignore_trivia=false.\n\nversion (default VERSION) may be used to set the syntax version to any Julia version >= v\"1.0\". We aim to parse all Julia syntax which has been added after v\"1.0\", emitting an error if it's not compatible with the requested version.\n\nPass filename to set any file name information embedded within the output tree, if applicable. This will also annotate errors and warnings with the source file name.\n\nA ParseError will be thrown if any errors or warnings occurred during parsing. To avoid exceptions due to warnings, use ignore_warnings=true. To also avoid exceptions due to errors, use ignore_errors=true.\n\n\n\n\n\n","category":"function"},{"location":"api/#Low-level-parsing-API","page":"API Reference","title":"Low level parsing API","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"The ParseStream interface which provides a low-level stream-like I/O interface for writing the parser. The parser does not depend on or produce any concrete tree data structure as part of the parsing phase but the output spans can be post-processed into various tree data structures as required using JuliaSyntax.build_tree.","category":"page"},{"location":"api/","page":"API Reference","title":"API Reference","text":"JuliaSyntax.parse!\nJuliaSyntax.ParseStream\nJuliaSyntax.build_tree","category":"page"},{"location":"api/#JuliaSyntax.parse!","page":"API Reference","title":"JuliaSyntax.parse!","text":"parse!(stream::ParseStream; rule=:all)\n\nParse Julia source code from a ParseStream object. Output tree data structures may be extracted from stream with the build_tree function.\n\nrule may be any of\n\n:all (default) — parse a whole \"file\" of top level statements. In this mode, the parser expects to fully consume the input.\n:statement — parse a single statement, or statements separated by semicolons.\n:atom — parse a single syntax \"atom\": a literal, identifier, or parenthesized expression.\n\n\n\n\n\nparse!(TreeType, io::IO; rule=:all, version=VERSION)\n\nParse Julia source code from a seekable IO object. The output is a tuple (tree, diagnostics). When parse! returns, the stream io is positioned directly after the last byte which was consumed during parsing.\n\n\n\n\n\n","category":"function"},{"location":"api/#JuliaSyntax.ParseStream","page":"API Reference","title":"JuliaSyntax.ParseStream","text":"ParseStream(text::AbstractString,          index::Integer=1; version=VERSION)\nParseStream(text::IO;                                        version=VERSION)\nParseStream(text::Vector{UInt8},           index::Integer=1; version=VERSION)\nParseStream(ptr::Ptr{UInt8}, len::Integer, index::Integer=1; version=VERSION)\n\nConstruct a ParseStream from input which may come in various forms:\n\nAn string (zero copy for String and SubString)\nAn IO object (zero copy for IOBuffer). The IO object must be seekable.\nA buffer of bytes (zero copy). The caller is responsible for preserving buffers passed as (ptr,len).\n\nA byte index may be provided as the position to start parsing.\n\nParseStream provides an IO interface for the parser which provides lexing of the source text input into tokens, manages insignificant whitespace tokens on behalf of the parser, and stores output tokens and tree nodes in a pair of output arrays.\n\nversion (default VERSION) may be used to set the syntax version to any Julia version >= v\"1.0\". We aim to parse all Julia syntax which has been added after v\"1.0\", emitting an error if it's not compatible with the requested version.\n\n\n\n\n\n","category":"type"},{"location":"api/#JuliaSyntax.build_tree","page":"API Reference","title":"JuliaSyntax.build_tree","text":"build_tree(make_node::Function, ::Type{StackEntry}, stream::ParseStream; kws...)\n\nConstruct a tree from a ParseStream using depth-first traversal. make_node must have the signature\n\nmake_node(head::SyntaxHead, span::Integer, children)\n\nwhere children is either nothing for leaf nodes or an iterable of the children of type StackEntry for internal nodes. StackEntry may be a node type, but also may include other information required during building the tree.\n\nIf the ParseStream has multiple nodes at the top level, K\"wrapper\" is used to wrap them in a single node.\n\nThe tree here is constructed depth-first in postorder.\n\n\n\n\n\n","category":"function"},{"location":"api/#Tokenization","page":"API Reference","title":"Tokenization","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"JuliaSyntax.tokenize\nJuliaSyntax.untokenize\nJuliaSyntax.Token","category":"page"},{"location":"api/#JuliaSyntax.tokenize","page":"API Reference","title":"JuliaSyntax.tokenize","text":"tokenize(text)\n\nReturns the tokenized UTF-8 encoded text as a vector of Tokens. The text for the token can be retreived by using untokenize(). The full text can be reconstructed with, for example, join(untokenize.(tokenize(text), text)).\n\nThis interface works on UTF-8 encoded string or buffer data only.\n\n\n\n\n\n","category":"function"},{"location":"api/#JuliaSyntax.untokenize","page":"API Reference","title":"JuliaSyntax.untokenize","text":"Return the string representation of a token kind, or nothing if the kind represents a class of tokens like K\"Identifier\".\n\nWhen unique=true only return a string when the kind uniquely defines the corresponding input token, otherwise return nothing.  When unique=false, return the name of the kind.\n\nTODO: Replace untokenize() with Base.string()?\n\n\n\n\n\n","category":"function"},{"location":"api/#JuliaSyntax.Token","page":"API Reference","title":"JuliaSyntax.Token","text":"Token type resulting from calling tokenize(text)\n\nUse\n\nkind(tok) to get the token kind\nuntokenize(tok, text) to retreive the text\nPredicates like is_error(tok) to query token categories and flags\n\n\n\n\n\n","category":"type"},{"location":"api/#Source-file-handling","page":"API Reference","title":"Source file handling","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"JuliaSyntax.SourceFile\nJuliaSyntax.highlight\nJuliaSyntax.sourcetext\nJuliaSyntax.source_line\nJuliaSyntax.source_location\nJuliaSyntax.source_line_range","category":"page"},{"location":"api/#JuliaSyntax.SourceFile","page":"API Reference","title":"JuliaSyntax.SourceFile","text":"SourceFile(code [; filename=nothing, first_line=1, first_index=1])\n\nUTF-8 source text with associated file name and line number, storing the character indices of the start of each line. first_line and first_index can be used to specify the line number and index of the first character of code within a larger piece of source text.\n\nSourceFile may be indexed via getindex or view to get a string.  Line information for a byte offset can be looked up via the source_line, source_location and source_line_range functions.\n\n\n\n\n\n","category":"type"},{"location":"api/#JuliaSyntax.highlight","page":"API Reference","title":"JuliaSyntax.highlight","text":"highlight(io::IO, source::SourceFile, range::UnitRange;\n          color, note, notecolor,\n          context_lines_before, context_lines_inner, context_lines_after,\nhighlight(io, x; kws...)\n\nPrint the lines of source code source surrounding the given byte range which is highlighted with background color and underlined with markers in the text. A note in notecolor may be provided as annotation.\n\nIn the second form, x is an object with sourcefile(x) and byte_range(x) implemented.\n\nThe context arguments context_lines_before, etc, refer to the number of lines of code which will be printed as context before and after, with inner referring to context lines inside a multiline region.\n\n\n\n\n\n","category":"function"},{"location":"api/#JuliaSyntax.sourcetext","page":"API Reference","title":"JuliaSyntax.sourcetext","text":"sourcetext(source::SourceFile)\n\nGet the full source text of a SourceFile as a string.\n\n\n\n\n\nsourcetext(node)\n\nGet the full source text of a node.\n\n\n\n\n\n","category":"function"},{"location":"api/#JuliaSyntax.source_line","page":"API Reference","title":"JuliaSyntax.source_line","text":"Get the line number at the given byte index.\n\n\n\n\n\n","category":"function"},{"location":"api/#JuliaSyntax.source_location","page":"API Reference","title":"JuliaSyntax.source_location","text":"Get line number and character within the line at the given byte index.\n\n\n\n\n\n","category":"function"},{"location":"api/#JuliaSyntax.source_line_range","page":"API Reference","title":"JuliaSyntax.source_line_range","text":"Get byte range of the source line at byteindex, buffered by `contextlinesbeforeandcontextlines_after` before and after.\n\n\n\n\n\n","category":"function"},{"location":"api/#Expression-heads/kinds","page":"API Reference","title":"Expression heads/kinds","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"JuliaSyntax.Kind\nJuliaSyntax.SyntaxHead\nJuliaSyntax.@K_str\nJuliaSyntax.kind\nJuliaSyntax.head\nJuliaSyntax.flags","category":"page"},{"location":"api/#JuliaSyntax.Kind","page":"API Reference","title":"JuliaSyntax.Kind","text":"K\"name\"\nKind(namestr)\n\nKind is a type tag for specifying the type of tokens and interior nodes of a syntax tree. Abstractly, this tag is used to define our own sum types for syntax tree nodes. We do this explicitly outside the Julia type system because (a) Julia doesn't have sum types and (b) we want concrete data structures which are unityped from the Julia compiler's point of view, for efficiency.\n\nNaming rules:\n\nKinds which correspond to exactly one textural form are represented with that text. This includes keywords like K\"for\" and operators like K\"*\".\nKinds which represent many textural forms have UpperCamelCase names. This includes kinds like K\"Identifier\" and K\"Comment\".\nKinds which exist merely as delimiters are all uppercase\n\n\n\n\n\n","category":"type"},{"location":"api/#JuliaSyntax.SyntaxHead","page":"API Reference","title":"JuliaSyntax.SyntaxHead","text":"SyntaxHead(kind, flags)\n\nA SyntaxHead combines the Kind of a syntactic construct with a set of flags. The kind defines the broad \"type\" of the syntactic construct, while the flag bits compactly store more detailed information about the construct.\n\n\n\n\n\n","category":"type"},{"location":"api/#JuliaSyntax.@K_str","page":"API Reference","title":"JuliaSyntax.@K_str","text":"K\"s\"\n\nThe kind of a token or AST internal node with string \"s\".\n\nFor example\n\nK\")\" is the kind of the right parenthesis token\nK\"block\" is the kind of a block of code (eg, statements within a begin-end).\n\n\n\n\n\n","category":"macro"},{"location":"api/#JuliaSyntax.kind","page":"API Reference","title":"JuliaSyntax.kind","text":"kind(x)\n\nReturn the Kind of x.\n\n\n\n\n\n","category":"function"},{"location":"api/#JuliaSyntax.head","page":"API Reference","title":"JuliaSyntax.head","text":"head(x)\n\nGet the SyntaxHead of a node of a tree or other syntax-related data structure.\n\n\n\n\n\n","category":"function"},{"location":"api/#JuliaSyntax.flags","page":"API Reference","title":"JuliaSyntax.flags","text":"flags(x)\n\nReturn the flag bits of a syntactic construct. Prefer to query these with the predicates is_trivia, is_prefix_call, is_infix_op_call, is_prefix_op_call, is_postfix_op_call, is_dotted, is_suffixed, is_decorated.\n\nOr extract numeric portion of the flags with numeric_flags.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API Reference","title":"API Reference","text":"see also predicates related to flags.","category":"page"},{"location":"api/#Syntax-trees","page":"API Reference","title":"Syntax trees","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Syntax tree types:","category":"page"},{"location":"api/","page":"API Reference","title":"API Reference","text":"JuliaSyntax.SyntaxNode\nJuliaSyntax.GreenNode","category":"page"},{"location":"api/#JuliaSyntax.SyntaxNode","page":"API Reference","title":"JuliaSyntax.SyntaxNode","text":"SyntaxNode(source::SourceFile, raw::GreenNode{SyntaxHead};\n           keep_parens=false, position::Integer=1)\n\nAn AST node with a similar layout to Expr. Typically constructed from source text by calling one of the parser API functions such as parseall\n\n\n\n\n\n","category":"type"},{"location":"api/#JuliaSyntax.GreenNode","page":"API Reference","title":"JuliaSyntax.GreenNode","text":"GreenNode(head, span)\nGreenNode(head, children...)\n\nA \"green tree\" is a lossless syntax tree which overlays all the source text. The most basic properties of a green tree are that:\n\nNodes cover a contiguous span of bytes in the text\nSibling nodes are ordered in the same order as the text\n\nAs implementation choices, we choose that:\n\nNodes are immutable and don't know their parents or absolute position, so can be cached and reused\nNodes are homogenously typed at the language level so they can be stored concretely, with the head defining the node type. Normally this would include a \"syntax kind\" enumeration, but it can also include flags and record information the parser knew about the layout of the child nodes.\nFor simplicity and uniformity, leaf nodes cover a single token in the source. This is like rust-analyzer, but different from Roslyn where leaves can include syntax trivia.\n\n\n\n\n\n","category":"type"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Functions applicable to syntax trees include everything in the sections on heads/kinds, and source file handling.","category":"page"},{"location":"api/","page":"API Reference","title":"API Reference","text":"JuliaSyntax.byte_range","category":"page"},{"location":"api/#JuliaSyntax.byte_range","page":"API Reference","title":"JuliaSyntax.byte_range","text":"byte_range(ex)\n\nReturn the range of bytes which ex covers in the source text.\n\n\n\n\n\n","category":"function"},{"location":"design/#Design-discussion-and-developer-documentation","page":"Design Discussion","title":"Design discussion and developer documentation","text":"","category":"section"},{"location":"design/#Goals","page":"Design Discussion","title":"Goals","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Lossless parsing of Julia code with precise source mapping\nProduction quality error recovery, reporting and unit testing\nParser structure similar to Julia's flisp-based parser\nSpeedy enough for interactive editing\n\"Compilation as an API\" to support all sorts of tooling\nGrow to encompass the rest of the compiler frontend: macro expansion, desugaring and other lowering steps.\nReplace Julia's flisp-based reference frontend","category":"page"},{"location":"design/#Design-Opinions","page":"Design Discussion","title":"Design Opinions","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Parser implementation should be independent from tree data structures. So we have the ParseStream interface.\nTree data structures should be layered to balance losslessness with abstraction and generality. So we have SyntaxNode (an AST) layered on top of GreenNode (a lossless parse tree). We might need other tree types later.\nFancy parser generators still seem marginal for production compilers. We use a boring but flexible recursive descent parser.","category":"page"},{"location":"design/#Parser-implementation","page":"Design Discussion","title":"Parser implementation","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Our goal is to losslessly represent the source text with a tree; this may be called a \"lossless syntax tree\". (This is sometimes called a \"concrete syntax tree\", but that term has also been used for the parse tree of the full formal grammar for a language including any grammar hacks required to solve ambiguities, etc. So we avoid this term.)","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"JuliaSyntax uses a mostly recursive descent parser which closely follows the high level structure of the flisp reference parser. This makes the code familiar and reduces porting bugs. It also gives a lot of flexibility for designing the diagnostics, tree data structures, compatibility with different Julia versions, etc. I didn't choose a parser generator as they still seem marginal for production compilers — for the parsing itself they don't seem greatly more expressive and they can be less flexible for the important \"auxiliary\" code which needs to be written in either case.","category":"page"},{"location":"design/#Lexing","page":"Design Discussion","title":"Lexing","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"We use a hand-written lexer (a heavily modified version of Tokenize.jl)","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Newline-containing whitespace is emitted as a separate kind\nTokens inside string interpolations are emitted separately from the string\nStrings delimiters are separate tokens and the actual string always has the String kind\nAdditional contextual keywords (as, var, doc) have been added and moved to a subcategory of keywords.\nNonterminal kinds were added (though these should probably be factored out again)\nVarious bugs fixed and additions for newer Julia versions","category":"page"},{"location":"design/#Parsing-with-ParseStream","page":"Design Discussion","title":"Parsing with ParseStream","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"The main parser innovation is the ParseStream interface which provides a stream-like I/O interface for writing the parser. The parser does not depend on or produce any concrete tree data structure as part of the parsing phase but the output spans can be post-processed into various tree data structures as required. This is like the design of rust-analyzer though with a simpler implementation.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Parsing proceeds by recursive descent;","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"The parser consumes a flat list of lexed tokens as input using peek() to examine tokens and bump() to consume them.\nThe parser produces a flat list of text spans as output using bump() to transfer tokens to the output and position()/emit() for nonterminal ranges.\nDiagnostics are emitted as separate text spans\nWhitespace and comments are automatically bump()ed and don't need to be handled explicitly. The exception is syntactically relevant newlines in space sensitive mode.\nParser modes are passed down the call tree using ParseState.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"The output spans track the byte range, a syntax \"kind\" stored as an integer tag, and some flags. The kind tag makes the spans a sum type but where the type is tracked explicitly outside of Julia's type system.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"For lossless parsing the output spans must cover the entire input text. Using bump(), position() and emit() in a natural way also ensures that:","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Spans are cleanly nested with children contained entirely within their parents\nSiblings spans are emitted in source order\nParent spans are emitted after all their children.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"These properties make the output spans naturally isomorphic to a \"green tree\" in the terminology of C#'s Roslyn compiler.","category":"page"},{"location":"design/#Tree-construction","page":"Design Discussion","title":"Tree construction","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"The build_tree function performs a depth-first traversal of the ParseStream output spans allowing it to be assembled into a concrete tree data structure, for example using the GreenNode data type. We further build on top of this to define build_tree for the AST type SyntaxNode and for normal Julia Expr.","category":"page"},{"location":"design/#Error-recovery","page":"Design Discussion","title":"Error recovery","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"The goal of the parser is to produce well-formed hierarchical structure from the source text. For interactive tools we need this to work even when the source text contains errors; it's the job of the parser to include the recovery heuristics to make this work.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Concretely, the parser in JuliaSyntax should always produce a green tree which is well formed in the sense that GreenNodes of a given Kind have well-defined layout of children. This means the GreenNode to SyntaxNode transformation is deterministic and tools can assume they're working with a \"mostly valid\" AST.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"What does \"mostly valid\" mean? We allow the tree to contain the following types of error nodes:","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Missing tokens or nodes may be added as placeholders when they're needed to complete a piece of syntax. For example, we could parse a + (b * as (call-i a + (call-i * b XXX)) where XXX is a placeholder error node.\nA sequence of unexpected tokens may be removed by collecting them as children of an error node and treating them as syntax trivia during AST construction. For example, a + b end * c could be parsed as the green tree (call-i a + b (error-t end * c)), and turned into the AST (call + a b).","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"We want to encode both these cases in a way which is simplest for downstream tools to use. This is an open question, but for now we use K\"error\" as the kind, with the TRIVIA_FLAG set for unexpected syntax.","category":"page"},{"location":"design/#Syntax-trees","page":"Design Discussion","title":"Syntax trees","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Julia's Expr abstract syntax tree can't store precise source locations or deal with syntax trivia like whitespace or comments. So we need some new tree types in JuliaSyntax.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"JuliaSyntax currently deals in three types of trees:","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"GreenNode is a minimal lossless syntax tree where\nNodes store a kind and length in bytes, but no text\nSyntax trivia are included in the list of children\nChildren are strictly in source order\nSyntaxNode is an abstract syntax tree which has\nAn absolute position and pointer to the source text\nChildren strictly in source order\nLeaf nodes store values, not text\nTrivia are ignored, but there is a 1:1 mapping of non-trivia nodes to the associated GreenTree nodes.\nExpr is used as a conversion target for compatibility","category":"page"},{"location":"design/#More-about-syntax-kinds","page":"Design Discussion","title":"More about syntax kinds","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"We generally track the type of syntax nodes with a syntax \"kind\", stored explicitly in each node an integer tag. This effectively makes the node type a sum type in the type system sense, but with the type tracked explicitly outside of Julia's type system.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Managing the type explicitly brings a few benefits:","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Code and data structures for manipulating syntax nodes is always concretely typed from the point of view of the compiler.\nWe control the data layout and can pack the kind into very few bits along with other flags bits, as desired.\nPredicates such as is_operator can be extremely efficient, given that we know the meaning of the kind's bits.\nThe kind can be applied to several different tree data structures, or manipulated by itself.\nPattern matching code is efficient when the full set of kinds is closed and known during compilation.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"There's arguably a few downsides:","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Normal Julia dispatch can't express dispatch over syntax kind. Luckily, a pattern matching macro can provide a very elegant way of expressing such algorithms over a non-extensible set of kinds, so this is not a big problem.\nDifferent node kinds could come with different data fields, but a syntax tree must have generic fields to cater for all kinds. (Consider as an analogy the normal Julia AST QuoteNode with a single field vs Expr with generic head and args fields.) This could be a disadvantage for code which processes one specific kind but for generic code processing many kinds having a generic but concrete data layout should be faster.","category":"page"},{"location":"design/#Differences-from-the-flisp-parser","page":"Design Discussion","title":"Differences from the flisp parser","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"See also the § Comparisons to other packages section.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Practically the flisp parser is not quite a classic recursive descent parser, because it often looks back and modifies the output tree it has already produced. We've tried to eliminate this pattern in favor of lookahead where possible because","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"It works poorly when the parser is emitting a stream of node spans with strict source ordering constraints.\nIt's confusing to reason about this kind of code","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"However, on occasion it seems to solve genuine ambiguities where Julia code can't be parsed top-down with finite lookahead. Eg for the kw vs = ambiguity within parentheses. In these cases we put up with using the functions look_behind and reset_node!().","category":"page"},{"location":"design/#Code-structure","page":"Design Discussion","title":"Code structure","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Large structural changes were generally avoided while porting. In particular, nearly all function names for parsing productions are the same with - replaced by _ and predicates prefixed by is_.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Some notable differences:","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"parse-arglist and a parts of parse-paren- have been combined into a general function parse_brackets. This function deals with all the odd corner cases of how the AST is emitted when mixing , and ; within parentheses. In particular regard to:\nDetermining whether ; are block syntax separators or keyword parameters\nDetermining whether to emit parameter sections based on context\nEmitting key-value pairs either as kw or = depending on context\nThe way that parse-resword is entered has been rearranged to avoid parsing reserved words with parse-atom inside parse-unary-prefix. Instead, we detect reserved words and enter parse_resword earlier.","category":"page"},{"location":"design/#Flisp-parser-bugs","page":"Design Discussion","title":"Flisp parser bugs","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Here's some behaviors which seem to be bugs. (Some of these we replicate in the name of compatibility, perhaps with a warning.)","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Macro module paths allow calls which gives weird stateful semantics!\nb() = rand() > 0.5 ? Base : Core\nb().@info \"hi\"\nMisplaced @ in macro module paths like A.@B.x is parsed as odd broken-looking AST like (macrocall (. A (quote (. B @x)))).  It should probably be rejected.\nOperator prefix call syntax doesn't work in the cases like +(a;b,c) where keyword parameters are separated by commas. A tuple is produced instead.\nconst and global allow chained assignment, but the right hand side is not constant. a const here but not b.\nconst a = b = 1\nParsing the ncat array concatenation syntax within braces gives strange AST: {a ;; b} parses to (bracescat 2 a b) which is the same as {2 ; a ; b}, but should probably be (bracescat (nrow 2 a b)) in analogy to how {a b} produces (bracescat (row a b)).\nexport a, \\n $b is rejected, but export a, \\n b parses fine.\nIn try-catch-finally, the finally clause is allowed before the catch, but always executes afterward. (Presumably was this a mistake? It seems pretty awful!)\nWhen parsing \"[x \\n\\n ]\" the flisp parser gets confused, but \"[x \\n ]\" is correctly parsed as Expr(:vect) (maybe fixed in 1.7?)\nf(x for x in in xs) is accepted, and parsed very strangely.\nOctal escape sequences saturate rather than being reported as errors. Eg, \"\\777\" results in \"\\xff\".  This is inconsistent with Base.parse(::Type{Int}, ...)\nLeading dots in import paths with operator-named modules are parsed into dotted operators rather than a relative path. Ie, we have import .⋆ parsing to (import (. .⋆)) whereas it should be (import (. . ⋆)) for consistency with the parsing of import .A.\nLooking back on the output disregards grouping parentheses which can lead to odd results in some cases. For example, f(((((x=1))))) parses as a keyword call to function f with the keyword x=1, but arguably it should be an assignment.\nHexfloat literals can have a trailing f for example, 0x1p1f but this doesn't do anything. In the flisp C code such cases are treated as Float32 literals and this was intentional https://github.com/JuliaLang/julia/pull/2925 but this has never been officially supported in Julia. It seems this bug arises from (set! pred char-hex?) in parse-number accepting hex exponent digits, all of which are detected as invalid except for a trailing f when processed by isnumtok_base.\nbegin and end are not parsed as keywords when indexing. Typed comprehensions initially look the same, but can be distinguished from indexing once we handle a for token; it is safe to treat begin and end as keywords afterwards. The reference parser only handles this well when there's a newline before for:\nAny[foo(i)\n    for i in x if begin\n        true\n    end\n]\nworks, while\nAny[foo(i) for i in x if begin\n        true\n    end\n]\ndoes not. JuliaSyntax handles both cases.","category":"page"},{"location":"design/#Parsing-/-AST-oddities-and-warts","page":"Design Discussion","title":"Parsing / AST oddities and warts","text":"","category":"section"},{"location":"design/#Questionable-allowed-forms","page":"Design Discussion","title":"Questionable allowed forms","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"There's various allowed syntaxes which are fairly easily detected in the parser, but which will be rejected later during lowering. To allow building DSLs this is fine and good but some such allowed syntaxes don't seem very useful, even for DSLs:","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"macro (x) end is allowed but there are no anonymous macros.\nabstract type A < B end and other subtype comparisons are allowed, but only A <: B makes sense.\nx where {S T} produces (where x (bracescat (row S T))). This seems pretty weird!\n[x for outer x in xs] parses, but outer makes no real sense in this context (and using this form is a lowering error)","category":"page"},{"location":"design/#kw-and-inconsistencies","page":"Design Discussion","title":"kw and = inconsistencies","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"There's many apparent inconsistencies between how kw and = are used when parsing key=val pairs inside parentheses.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Inconsistent parsing of tuple keyword args inside vs outside of dot calls\n(a=1,)           # (tuple (= a 1))\nf.(a=1)          # (tuple (kw a 1))\nMixtures of , and ; in calls give nested parameter AST which parses strangely, and is kind-of-horrible to use.\n# (tuple (parameters (parameters e f) c d) a b)\n(a,b; c,d; e,f)\nLong-form anonymous functions have argument lists which are parsed as tuples (or blocks!) rather than argument lists and this mess appears to be papered over as part of lowering. For example, in function (a;b) end the (a;b) is parsed as a block! This leads to more inconsistency in the use of kw for keywords.","category":"page"},{"location":"design/#Other-oddities","page":"Design Discussion","title":"Other oddities","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Operators with suffices don't seem to always be parsed consistently as the same operator without a suffix. Unclear whether this is by design or mistake. For example, [x +y] ==> (hcat x (+ y)), but [x +₁y] ==> (hcat (call +₁ x y))\nglobal const x=1 is normalized by the parser into (const (global (= x 1))). I suppose this is somewhat useful for AST consumers, but reversing the source order is pretty weird and inconvenient when moving to a lossless parser.\nlet bindings might be stored in a block, or they might not be, depending on special cases:\n# Special cases not in a block\nlet x=1 ; end   # ==>  (let (= x 1) (block))\nlet x::1 ; end  # ==>  (let (:: x 1) (block))\nlet x ; end     # ==>  (let x (block))\n\n# In a block\nlet x=1,y=2 ; end  # ==>  (let (block (= x 1) (= y 2) (block)))\nlet x+=1 ; end     # ==>  (let (block (+= x 1)) (block))\nThe elseif condition is always in a block but not the if condition. Presumably because of the need to add a line number node in the flisp parser if a xx elseif b yy end   ==>  (if a (block xx) (elseif (block b) (block yy)))\nSpaces are allowed between import dots — import . .A is allowed, and parsed the same as import ..A\nimport A.. produces (import (. A .)) which is arguably nonsensical, as . can't be a normal identifier.\nThe raw string escaping rules are super confusing for backslashes near the end of the string: raw\"\\\\\\\\ \" contains four backslashes, whereas raw\"\\\\\\\\\" contains only two. However this was an intentional feature to allow all strings to be represented and it's unclear whether the situation can be improved.\nIn braces after macrocall, @S{a b} is invalid but both @S{a,b} and @S {a b} parse. Conversely, @S[a b] parses.\nMacro names and invocations are post-processed from the output of parse-atom / parse-call, which leads to some surprising and questionable constructs which \"work\":\nAbsurdities like @(((((a))))) x ==> (macrocall @a x)\nInfix macros!? @(x + y)  ==>  (macrocall @+ x y) (ok, kinda cute and has some weird logic to it... but what?)\nSimilarly additional parentheses are allowed @(f(x)) ==> (macrocall @f x)\nAllowing @ first in macro module paths (eg @A.B.x instead of A.B.@x) seems like unnecessary variation in syntax. It makes parsing valid macro module paths more complex and leads to oddities like @$.x y ==> (macrocall ($ (quote x)) y where the $ is first parsed as a macro name, but turns out to be the module name after the . is parsed. But $ can never be a valid module name in normal Julia code so this makes no sense.\nTriple quoted var\"\"\"##\"\"\" identifiers are allowed. But it's not clear these are required or desired given that they come with the complex triple-quoted string deindentation rules.\nDeindentation of triple quoted strings with mismatched whitespace is weird when there's nothing but whitespace. For example, we have \"\\\"\\\"\\\"\\n  \\n \\n  \\\"\\\"\\\"\" ==> \"\\n \\n\" so the middle line of whitespace here isn't dedented but the other two longer lines are?? Here it seems more consistent that either (a) the middle line should be deindented completely, or (b) all lines should be dedented only one character, as that's the matching prefix.\nParsing of anonymous function arguments is somewhat inconsistent. function (xs...) \\n body end parses the argument list as (... xs), whereas function (x) \\n body end parses the argument list as (tuple x).\nThe difference between multidimensional vs flattened iterators is subtle, and perhaps too syntactically permissive.  For example,\n[(x,y) for x * in 1:10, y in 1:10] is a multidimensional iterator\n[(x,y) for x * in 1:10 for y in 1:10] is a flattened iterator\n[(x,y) for x in 1:10, y in 1:10 if y < x] is a flattened iterator\nIt's this last case which seems problematic (why not require the second form as a more explicit way to indicate flattening?). It's not even pretty printed correctly:\njulia> :([(x,y) for x in 1:10, y in 1:10 if y < x])\n:([(x, y) for $(Expr(:filter, :(y < x), :(x = 1:10), :(y = 1:10)))])\nThe character ' may be written without escaping as ''' rather than requiring the form '\\''.","category":"page"},{"location":"design/#Comparisons-to-other-packages","page":"Design Discussion","title":"Comparisons to other packages","text":"","category":"section"},{"location":"design/#Official-Julia-compiler","page":"Design Discussion","title":"Official Julia compiler","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"See also the § Differences from the flisp parser section.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"The official Julia compiler frontend lives in the Julia source tree. It's mostly contained in just a few files:","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"The parser in src/julia-parser.scm\nMacro expansion in src/ast.c and src/macroexpand.scm\nSyntax lowering in src/julia-syntax.scm\nThe flisp runtime and C extensions for Julia in src/flisp\nSupporting utility functions in a few other .scm and .c files.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"There's two issues with the official reference frontend which suggest a rewrite.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"First, there's no support for precise source locations and the existing data structures (bare flisp lists) can't easily be extended to add these. Fixing this would require changes to nearly all of the code.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Second, it's written in flisp: an aestheically pleasing, minimal but obscure implementation of Scheme. Learning Scheme is actually a good way to appreciate some of Julia's design inspiration, but it's quite a barrier for developers of Julia language tooling. (Flisp has no user-level documentation but non-schemers can refer to the Racket documentation which is quite compatible for basic things.) In addition to the social factors, having the embedded flisp interpreter and runtime with its own separate data structures and FFI is complex and inefficient.","category":"page"},{"location":"design/#JuliaParser.jl","page":"Design Discussion","title":"JuliaParser.jl","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"JuliaParser.jl was a direct port of Julia's flisp reference parser, but was abandoned around Julia 0.5 or so. Furthermore, it doesn't support lossless parsing, and adding that feature would amount to a full rewrite. Given its divergence with the flisp reference parser since Julia-0.5, it seemed better just to start anew from the reference parser instead.","category":"page"},{"location":"design/#Tokenize.jl","page":"Design Discussion","title":"Tokenize.jl","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Tokenize.jl is a fast lexer for Julia code. The code from Tokenize has been imported and used in JuliaSyntax, with some major modifications as discussed in the lexer implementation section.","category":"page"},{"location":"design/#CSTParser.jl","page":"Design Discussion","title":"CSTParser.jl","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"CSTParser.jl is a (mostly?) lossless parser with goals quite similar to JuliaParser. It is used extensively in the VSCode / LanguageServer / JuliaFormatter ecosystem. CSTParser is very useful, but I do find the implementation hard to understand, and I wanted to try a fresh approach with a focus on:","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"\"Production readiness\": Good docs, tests, diagnostics and maximum similarity with the flisp parser, with the goal of getting the new parser into Core.\nLearning from the latest ideas about composable parsing and data structures from outside Julia. In particular the implementation of rust-analyzer is very clean, well documented, and was a great source of inspiration.\nComposability of tree data structures — I feel like the trees should be layered somehow with a really lightweight green tree at the most basic level, similar to Roslyn or rust-analyzer. In comparison, CSTParser uses a more heavyweight non-layered data structure. Alternatively or additionally, have a common tree API with many concrete task-specific implementations.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"A big benefit of the JuliaSyntax parser is that it separates the parser code from the tree data structures entirely, which should give a lot of flexibility in experimenting with various tree representations.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"I also want JuliaSyntax to tackle macro expansion and other lowering steps, and provide APIs for this which can be used by both the core language and the editor tooling.","category":"page"},{"location":"design/#tree-sitter-julia","page":"Design Discussion","title":"tree-sitter-julia","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Using a modern production-ready parser generator like tree-sitter is an interesting option and some progress has already been made in tree-sitter-julia. But I feel like the grammars for parser generators are only marginally more expressive than writing the parser by hand, after accounting for the effort spent on the weird edge cases of a real language and writing the parser's tests and \"supporting code\".","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"On the other hand, a hand-written parser is completely flexible and can be mutually understood with the reference implementation, so I chose that approach for JuliaSyntax.","category":"page"},{"location":"design/#Resources","page":"Design Discussion","title":"Resources","text":"","category":"section"},{"location":"design/#Julia-issues","page":"Design Discussion","title":"Julia issues","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Here's a few links to relevant Julia issues.","category":"page"},{"location":"design/#Macro-expansion","page":"Design Discussion","title":"Macro expansion","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Automatic hygiene for macros https://github.com/JuliaLang/julia/pull/6910 — would be interesting to implement this in a new frontend.","category":"page"},{"location":"design/#Lowering","page":"Design Discussion","title":"Lowering","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"A partial implementation of lowering in Julia https://github.com/JuliaLang/julia/pull/32201 — some of this should be ported. (Last commit at https://github.com/JuliaLang/julia/tree/df61138fcf97d03dcbbba10e962571af9700db56/ )\nThe closure capture problem https://github.com/JuliaLang/julia/issues/15276 — would be interesting to see whether we can tackle some of the harder cases in a new implementation.","category":"page"},{"location":"design/#C#-Roslyn","page":"Design Discussion","title":"C# Roslyn","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Persistence, façades and Roslyn’s red-green trees","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Roslyn optimization overview\nLiterate C# Usage Example","category":"page"},{"location":"design/#Rust-analyzer","page":"Design Discussion","title":"Rust-analyzer","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"rust-analyzer seems to be very close to what I'm building here, and has come to the same conclusions on green tree layout with explicit trivia nodes.  Their document on internals here is great. Points of note:","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"They have three trees!\nGreen trees exactly like mine (pretty much all the same design decisions, including trivia storage). Though note that the team are still toying with the idea of using the Roslyn model of trivia.\nUntyped red syntax trees somewhat like mine, but much more minimal. For example, these don't attempt to reorder children.\nA typed AST layer with a type for each expression head. The AST searches for children by dynamically traversing the child list each time, rather than having a single canonical ordering or remembering the placement of children which the parser knew.\n\"Parser does not see whitespace nodes. Instead, they are attached to the tree in the TreeSink layer.\" This may be relevant to us - it's a pain to attach whitespace to otherwise significant tokens, and inefficient to allocate and pass around a dynamic list of whitespace trivia.\n\"In practice, incremental reparsing doesn't actually matter much for IDE use-cases, parsing from scratch seems to be fast enough.\" (I wonder why they've implemented incremental parsing then?)\nThere's various comments about macros... Rust macro expansion seems quite different from Julia (it appears it may be interleaved with parsing??)","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"In general I think it's unclear whether we want typed ASTs in Julia and we particularly need to deal with the fact that Expr is the existing public interface. Could we have Expr2 wrap SyntaxNode?","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"A related very useful set of blog posts which discuss using the rust syntax tree library (rowan) for representing of a non-rust toy language is here https://dev.to/cad97/lossless-syntax-trees-280c","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Not all the design decisions in rust-analyzer are finalized but the architecture document is a fantastic source of design inspiration.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Highlights:","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"\"The parser is independent of the particular tree structure and particular representation of the tokens. It transforms one flat stream of events into another flat stream of events.\"  This seems great, let's adopt it!\nTODO","category":"page"},{"location":"design/#RSLint","page":"Design Discussion","title":"RSLint","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"RSLint is a linter for javascript, built in Rust. It uses the same parsing infrastructure and green tree libraries rust-analyzer. There's an excellent and friendly high level overview of how all this works in the rslint parsing devdocs.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Points of note:","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Backtracking and restarting the parser on error is actually quite simple in the architecture we (mostly) share with rust-analyzer:\n... events allow us to cheaply backtrack the parser by simply draining the events and resetting the token source cursor back to some place.\nThe section on error recovery is interesting; they talk about various error recovery strategies.","category":"page"},{"location":"design/#Diagnostics","page":"Design Discussion","title":"Diagnostics","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"The paper P2429 - Concepts Error Messages for Humans is C++ centric, but has a nice review of quality error reporting in various compilers including Elm, ReasonML, Flow, D and Rust.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Some Rust-specific resources:","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"rustc_errors::Diagnostic\nThe source of the Rust compiler's diagnostics system:\nThe println! macro shows how these can be emitted from macros\nThe parser's diagnostics.rs","category":"page"},{"location":"design/#General-resources-about-parsing","page":"Design Discussion","title":"General resources about parsing","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Modern parser generator has a lot of practical notes on writing parsers. Highlights:\nEncourages writing tests for handwritten parsers as inline comments\nMentions Pratt parsers for simple operator precedence parsing. Good articles:\nFrom Aleksey Kladov (matklad - the main rust-analyzer author, etc)\nFrom Bob Nystrom (munificent - one of the Dart devs, etc\nSome discussion of error recovery\nSome notes about stateful lexers for parsing shell-like string interpolations: http://www.oilshell.org/blog/2017/12/17.html","category":"page"},{"location":"design/#Design-notes","page":"Design Discussion","title":"Design notes","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"The following are some fairly disorganized design notes covering a mixture of things which have already been done and musings about further work.","category":"page"},{"location":"design/#Prototyping-approach","page":"Design Discussion","title":"Prototyping approach","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"The tree datastructure design here is tricky:","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"The symbolic part of compilation (the compiler frontend) incrementally abstracts and transforms the source text, but errors along the way should refer back to the source.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"The tree must be a lossless representation of the source text\nSome aspects of the source text (comments, most whitespace) are irrelevant to parsing.\nMore aspects of the source text are irrelevant after we have an abstract syntax tree of the surface syntax. Some good examples here are the parentheses in 2*(x + y) and the explicit vs implicit multiplication symbol in 2*x vs 2x.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"There's various type of analyses","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"There's many useful ways to augment a syntax tree depending on use case.\nAnalysis algorithms should be able to act on any tree type, ignoring but carrying augmentations which they don't know about.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Having so many use cases suggests it might be best to have several different tree types with a common interface rather than one main abstract syntax tree type. But it seems useful to figure this out by prototyping several important work flows:","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Syntax transformations\nChoose some macros to implement. This is a basic test of mixing source trees from different files while preserving precise source locations. (Done in <test/syntax_interpolation.jl>.)\nFormatting\nRe-indent a file. This tests the handling of syntax trivia.\nRefactoring\nA pass to rename local variables. This tests how information from further down the compilation pipeline can be attached to the syntax tree and used to modify the source code.\nPrecise error reporting in lowering\nSyntax desugaring [a, b] = (c, d) should report \"invalid assignment location [a, b]\". But at a precise source location.\nTry something several layers deeper inside lowering? For example \"macro definition not allowed inside a local scope\"\nIncremental reparsing\nReparse a source file, given a byte range replacement","category":"page"},{"location":"design/#Tree-design","page":"Design Discussion","title":"Tree design","text":"","category":"section"},{"location":"design/#Raw-syntax-tree-/-Green-tree","page":"Design Discussion","title":"Raw syntax tree / Green tree","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Raw syntax tree (or \"Green tree\" in the terminology from Roslyn)","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"We want GreenNode to be","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"structurally minimal — For efficiency and generality\nimmutable            — For efficiency (& thread safety)\ncomplete             — To preserve parser knowledge\ntoken agnostic       — To allow use with any source language","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"The simplest idea possible is to have:","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Leaf nodes are a single token\nChildren are in source order","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Call represents a challenge for the AST vs Green tree in terms of node placement / iteration for infix operators vs normal prefix function calls.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"The normal problem of a + 1 vs +(a, 1)\nOr worse, a + 1 + 2 vs +(a, 1, 2)","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Clearly in the AST's interface we need to abstract over this placement. For example with something like the normal Julia AST's iteration order.","category":"page"},{"location":"design/#Abstract-syntax-tree","page":"Design Discussion","title":"Abstract syntax tree","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"By pointing to green tree nodes, AST nodes become traceable back to the original source.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Unlike most languages, designing a new AST is tricky because the existing Expr is a very public API used in every macro expansion. User-defined macro expansions interpose between the source text and lowering, and using Expr looses source information in many ways.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"There seems to be a few ways forward:","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Maybe we can give Expr some new semi-hidden fields to point back to the green tree nodes that the Expr or its args list came from?\nWe can use the existing Expr during macro expansion and try to recover source information after macro expansion using heuristics. Likely the presence of correct hygiene can help with this.\nIntroducing a new AST would be possible if it were opt-in for some hypothetical \"new-style macros\" only. Fixing hygiene should go along with this. Design challenge: How do we make manipulating expressions reasonable when literals need to carry source location?","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"One option which may help bridge between locationless ASTs and something new may be to have wrappers for the small number of literal types we need to cover. For example:","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"SourceSymbol <: AbstractSymbol\nSourceInt    <: Integer\nSourceString <: AbstractString","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Having source location attached to symbols would potentially solve most of the hygiene problem. There's still the problem of macro helper functions which use symbol literals; we can't very well be changing the meaning of :x! Perhaps the trick there is to try capturing the current module at the location of the interpolation syntax. Eg, if you do :(y + $x), lowering expands this to Core._expr(:call, :+, :y, x), but it could expand it to something like Core._expr(:call, :+, :y, _add_source_symbol(_module_we_are_lowering_into, x))?","category":"page"},{"location":"design/#Parsing","page":"Design Discussion","title":"Parsing","text":"","category":"section"},{"location":"design/#Error-recovery-2","page":"Design Discussion","title":"Error recovery","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Some disorganized musings about error recovery","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Different types of errors seem to occur...","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Disallowed syntax (such as lack of spaces in conditional expressions) where we can reasonably just continue parsing and emit the node with an error flag which is otherwise fully formed. In some cases like parsing infix expressions with a missing tail, emitting a zero width error token can lead to a fully formed parse tree without the productions up the stack needing to participate in recovery.\nA token which is disallowed in current context. Eg, = in parse_atom, or a closing token inside an infix expression. Here we can emit a K\"error\", but we can't descend further into the parse tree; we must pop several recursive frames off. Seems tricky!","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"A typical structure is as follows:","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"function parse_foo(ps)\n    mark = position(ps)\n    parse_bar(ps)  # What if this fails?\n    if peek(ps) == K\"some-token\"\n        bump(ps)\n        parse_baz(ps)  # What if this fails?\n        emit(ps, mark, K\"foo\")\n    end\nend","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Emitting plain error tokens are good in unfinished infix expressions:","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"begin\n    a = x +\nend","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"The \"missing end\" problem is tricky, as the intermediate syntax is valid; the problem is often only obvious until we get to EOF.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Missing end","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"function f()\n    begin\n        a = 10\nend\n\n# <-- Indentation would be wrong if g() was an inner function of f.\nfunction g()\nend","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"It seems like ideal error recovery would need to backtrack in this case. For example:","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Pop back to the frame which was parsing f()\nBacktrack through the parse events until we find a function with indentation mismatched to the nesting of the parent.\nReset ParseStream to a parsing checkpoint before g() was called\nEmit error and exit the function parsing f()\nRestart parsing\nSomehow make sure all of this can't result in infinite recursion 😅","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Missing commas or closing brackets in nested structures also present the existing parser with a problem.","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"f(a,\n  g(b,\n    c    # -- missing comma?\n    d),\n  e)","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Again the local indentation might tell a story","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"f(a,\n  g(b,\n    c    # -- missing closing `)` ?\n  d)","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"But not always!","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"f(a,\n  g(b,\n    c    # -- missing closing `,` ?\n  d))","category":"page"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Another particularly difficult problem for diagnostics in the current system is broken parentheses or double quotes in string interpolations, especially when nested.","category":"page"},{"location":"design/#Fun-research-questions","page":"Design Discussion","title":"Fun research questions","text":"","category":"section"},{"location":"design/#Parser-Recovery","page":"Design Discussion","title":"Parser Recovery","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Can we learn fast and reasonably accurate recovery heuristics for when the parser encounters broken syntax, rather than hand-coding these? How would we set the parser up so that training works and injecting the model is nonintrusive? If the model is embedded in and works together with the parser, can it be made compact enough that training is fast and the model itself is tiny?","category":"page"},{"location":"design/#Formatting","page":"Design Discussion","title":"Formatting","text":"","category":"section"},{"location":"design/","page":"Design Discussion","title":"Design Discussion","text":"Given source and syntax tree, can we regress/learn a generative model of indentation from the syntax tree?  Source formatting involves a big pile of heuristics to get something which \"looks nice\"... and ML systems have become very good at heuristics. Also, we've got huge piles of training data — just choose some high quality, tastefully hand-formatted libraries.","category":"page"},{"location":"reference/#Syntax-Trees","page":"Syntax Trees","title":"Syntax Trees","text":"","category":"section"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"This section describes the syntax trees produced by JuliaSyntax, mainly in terms of their similarities and differences with the Expr tree data structures used since Julia 0.1.","category":"page"},{"location":"reference/#JuliaSyntax-trees-vs-Expr","page":"Syntax Trees","title":"JuliaSyntax trees vs Expr","text":"","category":"section"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"The tree structure of GreenNode/SyntaxNode is similar to Julia's Expr data structure but there are various differences:","category":"page"},{"location":"reference/#Source-ordered-children","page":"Syntax Trees","title":"Source ordered children","text":"","category":"section"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"The children of our trees are strictly in source order. This has many consequences in places where Expr reorders child expressions.","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"Infix and postfix operator calls have the operator name in the second child position. a + b is parsed as (call-i a + b) - where the infix -i flag indicates infix child position - rather than Expr(:call, :+, :a, :b).\nGenerators are represented in source order as a single node rather than multiple nested flatten and generator expressions.","category":"page"},{"location":"reference/#No-LineNumberNodes","page":"Syntax Trees","title":"No LineNumberNodes","text":"","category":"section"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"Our syntax nodes inherently stores source position, so there's no need for the LineNumberNodes used by Expr.","category":"page"},{"location":"reference/#More-consistent-/-less-redundant-blocks","page":"Syntax Trees","title":"More consistent / less redundant blocks","text":"","category":"section"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"Sometimes Expr needs redundant block constructs to store LineNumberNodes, but we don't need these. Also in cases which do use blocks we try to use them consistently.","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"No block is used on the right hand side of short form function syntax\nNo block is used for the conditional in elseif\nNo block is used for the body of anonymous functions after the ->\nlet argument lists always use a block regardless of number or form of bindings","category":"page"},{"location":"reference/#Faithful-representation-of-the-source-text-/-avoid-premature-lowering","page":"Syntax Trees","title":"Faithful representation of the source text / avoid premature lowering","text":"","category":"section"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"Some cases of \"premature lowering\" have been removed, preferring to represent the source text more closely.","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"K\"macrocall\" - allow users to easily distinguish macrocalls with parentheses from those without them (#218)\nGrouping parentheses are represented with a node of kind K\"parens\" (#222)\nThe right hand side of x where {T} retains the K\"braces\" node around the T to distinguish it from x where T.\nTernary syntax is not immediately lowered to an if node: a ? b : c parses as (? a b c) rather than Expr(:if, :a, :b, :c) (#85)\nglobal const and const global are not normalized by the parser. This is done in Expr conversion (#130)\ndo syntax is nested as the last child of the call which the do lambda will be passed to (#98, #322)\n@. is not lowered to @__dot__ inside the parser (#146)\nDocstrings use the K\"doc\" kind, and are not lowered to Core.@doc until later (#217)\nJuxtaposition uses the K\"juxtapose\" kind rather than lowering immediately to * (#220)\nreturn without a value has zero children, rather than lowering to return nothing (#220)","category":"page"},{"location":"reference/#Containers-for-string-like-constructs","page":"Syntax Trees","title":"Containers for string-like constructs","text":"","category":"section"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"String-like constructs always come within a container node, not as a single token. These are useful for tooling which works with the tokens of the source text. Also separating the delimiters from the text they delimit removes a whole class of tokenization errors and lets the parser deal with them.","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"string always use K\"string\" to wrap strings, even when they only contain a single string chunk (#94)\nchar literals are wrapped in the K\"char\" kind, containing the character literal string along with their delimiters (#121)\nbackticks use the K\"cmdstring\" kind\nvar\"\" syntax uses K\"var\" as the head (#127)\nThe parser splits triple quoted strings into string chunks interspersed with whitespace trivia","category":"page"},{"location":"reference/#Improvements-for-AST-inconsistencies","page":"Syntax Trees","title":"Improvements for AST inconsistencies","text":"","category":"section"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"Field access syntax like a.b is parsed as (. a b) rather than (. a (quote b)) to avoid the inconsistency between this and actual quoted syntax literals like :(b) and quote b end (#342)\nDotted call syntax like f.(a,b) and a .+ b has been made consistent with the K\"dotcall\" head (#90)\nStandalone dotted operators are always parsed as (. op). For example .*(x,y) is parsed as (call (. *) x y) (#240)\nThe K\"=\" kind is used for keyword syntax rather than kw, to avoid various inconsistencies and ambiguities (#103)\nUnadorned postfix adjoint is parsed as call rather than as a syntactic operator for consistency with suffixed versions like x'ᵀ (#124)","category":"page"},{"location":"reference/#Improvements-to-awkward-AST-forms","page":"Syntax Trees","title":"Improvements to awkward AST forms","text":"","category":"section"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"Frakentuples with multiple parameter blocks like (a=1, b=2; c=3; d=4) are flattened into the parent tuple instead of using nested K\"parameters\" nodes (#133)\nUsing try catch else finally end is parsed with K\"catch\" K\"else\" and K\"finally\" children to avoid the awkwardness of the optional child nodes in the Expr representation (#234)\nThe dotted import path syntax as in import A.b.c is parsed with a K\"importpath\" kind rather than K\".\", because a bare A.b.c has a very different nested/quoted expression representation (#244)\nWe use flags rather than child nodes to represent the difference between struct and mutable struct, module and baremodule (#220)\nMultiple iterations within the header of a for, as in for a=as, b=bs body end are represented with a cartesian_iterator head rather than a block, as these lists of iterators are neither semantically nor syntactically a sequence of statements. Unlike other uses of block (see also generators).","category":"page"},{"location":"reference/#More-detail-on-tree-differences","page":"Syntax Trees","title":"More detail on tree differences","text":"","category":"section"},{"location":"reference/#Generators","page":"Syntax Trees","title":"Generators","text":"","category":"section"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"Flattened generators are uniquely problematic because the Julia AST doesn't respect a key rule we normally expect: that the children of an AST node are a contiguous range in the source text. For example, the fors in [xy for x in xs for y in ys] are parsed in the normal order of a for loop to mean","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"for x in xs\nfor y in ys\n  push!(xy, collection)","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"so the xy prefix is in the body of the innermost for loop. Following this, the standard Julia AST is like so:","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"(flatten\n  (generator\n    (generator\n      xy\n      (= y ys))\n    (= x xs)))","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"however, note that if this tree were flattened, the order would be (xy) (y in ys) (x in xs) and the x and y iterations are opposite of the source order.","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"However, our green tree is strictly source-ordered, so we must deviate from the Julia AST. We deal with this by grouping cartesian products of iterators (separated by commas) within cartesian_iterator blocks as in for loops, and use the presence of multiple iterator blocks rather than the flatten head to distinguish flattened iterators. The nested flattens and generators of Expr forms are reconstructed later. In this form the tree structure resembles the source much more closely. For example, (xy for x in xs for y in ys) is parsed as","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"(generator\n  xy\n  (= x xs)\n  (= y ys))","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"And the cartesian iteration (xy for x in xs, y in ys) is parsed as","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"(generator\n  xy\n  (cartesian_iterator\n    (= x xs)\n    (= y ys)))","category":"page"},{"location":"reference/#Whitespace-trivia-inside-strings","page":"Syntax Trees","title":"Whitespace trivia inside strings","text":"","category":"section"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"For triple quoted strings, the indentation isn't part of the string data so should also be excluded from the string content within the green tree. That is, it should be treated as separate whitespace trivia tokens. With this separation things like formatting should be much easier. The same reasoning goes for escaping newlines and following whitespace with backslashes in normal strings.","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"Detecting string trivia during parsing means that string content is split over several tokens. Here we wrap these in the K\"string\" kind (as is already used for interpolations). The individual chunks can then be reassembled during Expr construction. (A possible alternative might be to reuse the K\"String\" and K\"CmdString\" kinds for groups of string chunks (without interpolation).)","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"Take as an example the following Julia fragment.","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"x = \"\"\"\n    $a\n    b\"\"\"","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"Here this is parsed as (= x (string-s a \"\\n\" \"b\")) (the -s flag in string-s means \"triple quoted string\")","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"Looking at the green tree, we see the indentation before the $a and b are marked as trivia:","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"julia> text = \"x = \\\"\\\"\\\"\\n    \\$a\\n    b\\\"\\\"\\\"\"\n       show(stdout, MIME\"text/plain\"(), parseall(GreenNode, text, rule=:statement), text)\n     1:23     │[=]\n     1:1      │  Identifier             ✔   \"x\"\n     2:2      │  Whitespace                 \" \"\n     3:3      │  =                          \"=\"\n     4:4      │  Whitespace                 \" \"\n     5:23     │  [string]\n     5:7      │    \"\"\"                      \"\\\"\\\"\\\"\"\n     8:8      │    String                   \"\\n\"\n     9:12     │    Whitespace               \"    \"\n    13:13     │    $                        \"\\$\"\n    14:14     │    Identifier           ✔   \"a\"\n    15:15     │    String               ✔   \"\\n\"\n    16:19     │    Whitespace               \"    \"\n    20:20     │    String               ✔   \"b\"\n    21:23     │    \"\"\"                      \"\\\"\\\"\\\"\"","category":"page"},{"location":"reference/#String-nodes-always-wrapped-in-K\"string\"-or-K\"cmdstring\"","page":"Syntax Trees","title":"String nodes always wrapped in K\"string\" or K\"cmdstring\"","text":"","category":"section"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"All strings are surrounded by a node of kind K\"string\", even non-interpolated literals, so \"x\" parses as (string \"x\"). This makes string handling simpler and more systematic because interpolations and triple strings with embedded trivia don't need to be treated differently. It also gives a container in which to attach the delimiting quotes.","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"The same goes for command strings which are always wrapped in K\"cmdstring\" regardless of whether they have multiple pieces (due to triple-quoted dedenting) or otherwise.","category":"page"},{"location":"reference/#Do-blocks","page":"Syntax Trees","title":"Do blocks","text":"","category":"section"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"do syntax is represented in the Expr AST with the do outside the call. This makes some sense syntactically (do appears as \"an operator\" after the function call).","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"However semantically this nesting is awkward because the lambda represented by the do block is passed to the call. This same problem occurs for the macro form @f(x) do \\n body end where the macro expander needs a special rule to expand nestings of the form Expr(:do, Expr(:macrocall ...), ...), rearranging the expression which are passed to this macro call rather than passing the expressions up the tree.","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"The implied closure is also lowered to a nested Expr(:->) expression, though it this somewhat premature to do this during parsing.","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"To resolve these problems we parse","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"@f(x, y) do a, b\\n body\\n end\nf(x, y) do a, b\\n body\\n end","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"by tacking the do onto the end of the call argument list:","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"(macrocall @f x y (do (tuple a b) body))\n(call f x y (do (tuple a b) body))","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"This achieves the following desirable properties","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"Content of do is nested inside the call which improves the match between AST and semantics\nMacro can be passed the syntax as-is rather than the macro expander rearranging syntax before passing it to the macro\nIn the future, a macro can detect when it's being passed do syntax rather than lambda syntax\ndo head is used uniformly for both call and macrocall\nWe preserve the source ordering properties we need for the green tree.","category":"page"},{"location":"reference/#Tree-structure-reference","page":"Syntax Trees","title":"Tree structure reference","text":"","category":"section"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"This section may eventually contain a full description of the Julia AST. For now, we describe a few of the more subtle features.","category":"page"},{"location":"reference/#Concatenation-syntax","page":"Syntax Trees","title":"Concatenation syntax","text":"","category":"section"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"Concatenation syntax comes in two syntax forms:","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"The traditional hcat/vcat/row which deal with concatenation or matrix construction along dimensions one and two.\nThe new ncat/nrow syntax which deals with concatenation or array construction along arbitrary dimensions.","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"We write ncat-3 for concatenation along the third dimension. (The 3 is stored in the head flags for SyntaxNode trees, and in the first arg for Expr trees.) Semantically the new syntax can work like the old:","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"ncat-1 is the same as vcat\nncat-2 is the same as hcat\nrow is the same as nrow-2","category":"page"},{"location":"reference/#Vertical-concatenation-(dimension-1)","page":"Syntax Trees","title":"Vertical concatenation (dimension 1)","text":"","category":"section"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"Vertical concatenation along dimension 1 can be done with semicolons or newlines","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"julia> print_tree(:([a\n                     b]))\nExpr(:vcat)\n├─ :a\n└─ :b\n\njulia> print_tree(:([a ; b]))\nExpr(:vcat)\n├─ :a\n└─ :b","category":"page"},{"location":"reference/#Horizontal-concatenation-(dimension-2)","page":"Syntax Trees","title":"Horizontal concatenation (dimension 2)","text":"","category":"section"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"For horizontal concatenation along dimension 2, use spaces or double semicolons","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"julia> print_tree(:([a b]))\nExpr(:hcat)\n├─ :a\n└─ :b\n\njulia> print_tree(:([a ;; b]))\nExpr(:ncat)\n├─ 2\n├─ :a\n└─ :b","category":"page"},{"location":"reference/#Mixed-concatenation","page":"Syntax Trees","title":"Mixed concatenation","text":"","category":"section"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"Concatenation along dimensions 1 and 2 can be done with spaces and single semicolons or newlines, producing a mixture of vcat and row expressions:","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"julia> print_tree(:([a b\n                     c d]))\n# OR\njulia> print_tree(:([a b ; c d]))\nExpr(:vcat)\n├─ Expr(:row)\n│  ├─ :a\n│  └─ :b\n└─ Expr(:row)\n   ├─ :c\n   └─ :d","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"General n-dimensional concatenation results in nested ncat and nrow, for example","category":"page"},{"location":"reference/","page":"Syntax Trees","title":"Syntax Trees","text":"julia> print_tree(:([a ; b ;; c ; d ;;; x]))\nExpr(:ncat)\n├─ 3\n├─ Expr(:nrow)\n│  ├─ 2\n│  ├─ Expr(:nrow)\n│  │  ├─ 1\n│  │  ├─ :a\n│  │  └─ :b\n│  └─ Expr(:nrow)\n│     ├─ 1\n│     ├─ :c\n│     └─ :d\n└─ :x","category":"page"},{"location":"#JuliaSyntax.jl","page":"Overview","title":"JuliaSyntax.jl","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"A Julia compiler frontend, written in Julia.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"A talk from JuliaCon 2022 covered some aspects of this package.","category":"page"},{"location":"#Examples","page":"Overview","title":"Examples","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"Here's what parsing of a small piece of code currently looks like in various forms. We'll use the JuliaSyntax.parsestmt function to demonstrate, there's also JuliaSyntax.parse! offering more fine-grained control.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"First, a source-ordered AST with SyntaxNode (call-i in the dump here means the call has the infix -i flag):","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"julia> using JuliaSyntax\n\njulia> parsestmt(SyntaxNode, \"(x + y)*z\", filename=\"foo.jl\")\nline:col│ tree                                   │ file_name\n   1:1  │[call-i]                                │foo.jl\n   1:1  │  [parens]\n   1:2  │    [call-i]\n   1:2  │      x\n   1:4  │      +\n   1:6  │      y\n   1:8  │  *\n   1:9  │  z","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Internally this has a full representation of all syntax trivia (whitespace and comments) as can be seen with the more raw \"green tree\" representation with GreenNode. Here ranges on the left are byte ranges, and ✔ flags nontrivia tokens. Note that the parentheses are trivia in the tree representation, despite being important for parsing.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"julia> text = \"(x + y)*z\"\n       greentree = parsestmt(JuliaSyntax.GreenNode, text)\n     1:9      │[call]\n     1:7      │  [parens]\n     1:1      │    (\n     2:6      │    [call]\n     2:2      │      Identifier         ✔\n     3:3      │      Whitespace\n     4:4      │      +                  ✔\n     5:5      │      Whitespace\n     6:6      │      Identifier         ✔\n     7:7      │    )\n     8:8      │  *                      ✔\n     9:9      │  Identifier             ✔","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"GreenNode stores only byte ranges, but the token strings can be shown by supplying the source text string:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"julia> show(stdout, MIME\"text/plain\"(), greentree, text)\n     1:9      │[call]\n     1:7      │  [parens]\n     1:1      │    (                        \"(\"\n     2:6      │    [call]\n     2:2      │      Identifier         ✔   \"x\"\n     3:3      │      Whitespace             \" \"\n     4:4      │      +                  ✔   \"+\"\n     5:5      │      Whitespace             \" \"\n     6:6      │      Identifier         ✔   \"y\"\n     7:7      │    )                        \")\"\n     8:8      │  *                      ✔   \"*\"\n     9:9      │  Identifier             ✔   \"z\"","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Julia Expr can also be produced:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"julia> JuliaSyntax.parsestmt(Expr, \"(x + y)*z\")\n:((x + y) * z)","category":"page"}]
}
