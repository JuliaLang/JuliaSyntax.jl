<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Design Discussion · JuliaSyntax.jl</title><meta name="title" content="Design Discussion · JuliaSyntax.jl"/><meta property="og:title" content="Design Discussion · JuliaSyntax.jl"/><meta property="twitter:title" content="Design Discussion · JuliaSyntax.jl"/><meta name="description" content="Documentation for JuliaSyntax.jl."/><meta property="og:description" content="Documentation for JuliaSyntax.jl."/><meta property="twitter:description" content="Documentation for JuliaSyntax.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">JuliaSyntax.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Overview</a></li><li><a class="tocitem" href="../howto/">How To</a></li><li><span class="tocitem">Reference</span><ul><li><a class="tocitem" href="../reference/">Syntax Trees</a></li><li><a class="tocitem" href="../api/">API Reference</a></li></ul></li><li class="is-active"><a class="tocitem" href>Design Discussion</a><ul class="internal"><li><a class="tocitem" href="#Goals"><span>Goals</span></a></li><li><a class="tocitem" href="#Design-Opinions"><span>Design Opinions</span></a></li><li class="toplevel"><a class="tocitem" href="#Parser-implementation"><span>Parser implementation</span></a></li><li class="toplevel"><a class="tocitem" href="#Syntax-trees"><span>Syntax trees</span></a></li><li><a class="tocitem" href="#More-about-syntax-kinds"><span>More about syntax kinds</span></a></li><li class="toplevel"><a class="tocitem" href="#Differences-from-the-flisp-parser"><span>Differences from the flisp parser</span></a></li><li><a class="tocitem" href="#Code-structure"><span>Code structure</span></a></li><li><a class="tocitem" href="#Flisp-parser-bugs"><span>Flisp parser bugs</span></a></li><li><a class="tocitem" href="#Parsing-/-AST-oddities-and-warts"><span>Parsing / AST oddities and warts</span></a></li><li class="toplevel"><a class="tocitem" href="#Comparisons-to-other-packages"><span>Comparisons to other packages</span></a></li><li class="toplevel"><a class="tocitem" href="#Resources"><span>Resources</span></a></li><li><a class="tocitem" href="#Julia-issues"><span>Julia issues</span></a></li><li><a class="tocitem" href="#C#-Roslyn"><span>C# Roslyn</span></a></li><li><a class="tocitem" href="#Rust-analyzer"><span>Rust-analyzer</span></a></li><li><a class="tocitem" href="#RSLint"><span>RSLint</span></a></li><li><a class="tocitem" href="#Diagnostics"><span>Diagnostics</span></a></li><li><a class="tocitem" href="#General-resources-about-parsing"><span>General resources about parsing</span></a></li><li class="toplevel"><a class="tocitem" href="#Design-notes"><span>Design notes</span></a></li><li><a class="tocitem" href="#Prototyping-approach"><span>Prototyping approach</span></a></li><li><a class="tocitem" href="#Tree-design"><span>Tree design</span></a></li><li><a class="tocitem" href="#Parsing"><span>Parsing</span></a></li><li class="toplevel"><a class="tocitem" href="#Fun-research-questions"><span>Fun research questions</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Design Discussion</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Design Discussion</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaLang/JuliaSyntax.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaLang/JuliaSyntax.jl/blob/main/docs/src/design.md#L" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Design-discussion-and-developer-documentation"><a class="docs-heading-anchor" href="#Design-discussion-and-developer-documentation">Design discussion and developer documentation</a><a id="Design-discussion-and-developer-documentation-1"></a><a class="docs-heading-anchor-permalink" href="#Design-discussion-and-developer-documentation" title="Permalink"></a></h1><h2 id="Goals"><a class="docs-heading-anchor" href="#Goals">Goals</a><a id="Goals-1"></a><a class="docs-heading-anchor-permalink" href="#Goals" title="Permalink"></a></h2><ul><li>Lossless parsing of Julia code with precise source mapping</li><li>Production quality error recovery, reporting and unit testing</li><li>Parser structure similar to Julia&#39;s flisp-based parser</li><li>Speedy enough for interactive editing</li><li>&quot;Compilation as an API&quot; to support all sorts of tooling</li><li>Grow to encompass the rest of the compiler frontend: macro expansion, desugaring and other lowering steps.</li><li>Replace Julia&#39;s flisp-based reference frontend</li></ul><h2 id="Design-Opinions"><a class="docs-heading-anchor" href="#Design-Opinions">Design Opinions</a><a id="Design-Opinions-1"></a><a class="docs-heading-anchor-permalink" href="#Design-Opinions" title="Permalink"></a></h2><ul><li>Parser implementation should be independent from tree data structures. So we have the <code>ParseStream</code> interface.</li><li>Tree data structures should be <em>layered</em> to balance losslessness with abstraction and generality. So we have <code>SyntaxNode</code> (an AST) layered on top of <code>GreenNode</code> (a lossless parse tree). We might need other tree types later.</li><li>Fancy parser generators still seem marginal for production compilers. We use a boring but flexible recursive descent parser.</li></ul><h1 id="Parser-implementation"><a class="docs-heading-anchor" href="#Parser-implementation">Parser implementation</a><a id="Parser-implementation-1"></a><a class="docs-heading-anchor-permalink" href="#Parser-implementation" title="Permalink"></a></h1><p>Our goal is to losslessly represent the source text with a tree; this may be called a &quot;lossless syntax tree&quot;. (This is sometimes called a &quot;concrete syntax tree&quot;, but that term has also been used for the parse tree of the full formal grammar for a language including any grammar hacks required to solve ambiguities, etc. So we avoid this term.)</p><p><code>JuliaSyntax</code> uses a mostly recursive descent parser which closely follows the high level structure of the flisp reference parser. This makes the code familiar and reduces porting bugs. It also gives a lot of flexibility for designing the diagnostics, tree data structures, compatibility with different Julia versions, etc. I didn&#39;t choose a parser generator as they still seem marginal for production compilers — for the parsing itself they don&#39;t seem <em>greatly</em> more expressive and they can be less flexible for the important &quot;auxiliary&quot; code which needs to be written in either case.</p><h3 id="Lexing"><a class="docs-heading-anchor" href="#Lexing">Lexing</a><a id="Lexing-1"></a><a class="docs-heading-anchor-permalink" href="#Lexing" title="Permalink"></a></h3><p>We use a hand-written lexer (a heavily modified version of <a href="https://github.com/JuliaLang/Tokenize.jl">Tokenize.jl</a>)</p><ul><li>Newline-containing whitespace is emitted as a separate kind</li><li>Tokens inside string interpolations are emitted separately from the string</li><li>Strings delimiters are separate tokens and the actual string always has the <code>String</code> kind</li><li>Additional contextual keywords (<code>as</code>, <code>var</code>, <code>doc</code>) have been added and moved to a subcategory of keywords.</li><li>Nonterminal kinds were added (though these should probably be factored out again)</li><li>Various bugs fixed and additions for newer Julia versions</li></ul><h3 id="Parsing-with-ParseStream"><a class="docs-heading-anchor" href="#Parsing-with-ParseStream">Parsing with ParseStream</a><a id="Parsing-with-ParseStream-1"></a><a class="docs-heading-anchor-permalink" href="#Parsing-with-ParseStream" title="Permalink"></a></h3><p>The main parser innovation is the <code>ParseStream</code> interface which provides a stream-like I/O interface for writing the parser. The parser does not depend on or produce any concrete tree data structure as part of the parsing phase but the output spans can be post-processed into various tree data structures as required. This is like the design of rust-analyzer though with a simpler implementation.</p><p>Parsing proceeds by recursive descent;</p><ul><li>The parser consumes a flat list of lexed tokens as <em>input</em> using <code>peek()</code> to examine tokens and <code>bump()</code> to consume them.</li><li>The parser produces a flat list of text spans as <em>output</em> using <code>bump()</code> to transfer tokens to the output and <code>position()</code>/<code>emit()</code> for nonterminal ranges.</li><li>Diagnostics are emitted as separate text spans</li><li>Whitespace and comments are automatically <code>bump()</code>ed and don&#39;t need to be handled explicitly. The exception is syntactically relevant newlines in space sensitive mode.</li><li>Parser modes are passed down the call tree using <code>ParseState</code>.</li></ul><p>The output spans track the byte range, a syntax &quot;kind&quot; stored as an integer tag, and some flags. The kind tag makes the spans a <a href="https://blog.waleedkhan.name/union-vs-sum-types/">sum type</a> but where the type is tracked explicitly outside of Julia&#39;s type system.</p><p>For lossless parsing the output spans must cover the entire input text. Using <code>bump()</code>, <code>position()</code> and <code>emit()</code> in a natural way also ensures that:</p><ul><li>Spans are cleanly nested with children contained entirely within their parents</li><li>Siblings spans are emitted in source order</li><li>Parent spans are emitted after all their children.</li></ul><p>These properties make the output spans naturally isomorphic to a <a href="#raw-syntax-tree--green-tree">&quot;green tree&quot;</a> in the terminology of C#&#39;s Roslyn compiler.</p><h3 id="Tree-construction"><a class="docs-heading-anchor" href="#Tree-construction">Tree construction</a><a id="Tree-construction-1"></a><a class="docs-heading-anchor-permalink" href="#Tree-construction" title="Permalink"></a></h3><p>The <code>build_tree</code> function performs a depth-first traversal of the <code>ParseStream</code> output spans allowing it to be assembled into a concrete tree data structure, for example using the <code>GreenNode</code> data type. We further build on top of this to define <code>build_tree</code> for the AST type <code>SyntaxNode</code> and for normal Julia <code>Expr</code>.</p><h3 id="Error-recovery"><a class="docs-heading-anchor" href="#Error-recovery">Error recovery</a><a id="Error-recovery-1"></a><a class="docs-heading-anchor-permalink" href="#Error-recovery" title="Permalink"></a></h3><p>The goal of the parser is to produce well-formed hierarchical structure from the source text. For interactive tools we need this to work even when the source text contains errors; it&#39;s the job of the parser to include the recovery heuristics to make this work.</p><p>Concretely, the parser in <code>JuliaSyntax</code> should always produce a green tree which is <em>well formed</em> in the sense that <code>GreenNode</code>s of a given <code>Kind</code> have well-defined layout of children. This means the <code>GreenNode</code> to <code>SyntaxNode</code> transformation is deterministic and tools can assume they&#39;re working with a &quot;mostly valid&quot; AST.</p><p>What does &quot;mostly valid&quot; mean? We allow the tree to contain the following types of error nodes:</p><ul><li>Missing tokens or nodes may be <strong>added</strong> as placeholders when they&#39;re needed to complete a piece of syntax. For example, we could parse <code>a + (b *</code> as <code>(call-i a + (call-i * b XXX))</code> where <code>XXX</code> is a placeholder error node.</li><li>A sequence of unexpected tokens may be <strong>removed</strong> by collecting them as children of an error node and treating them as syntax trivia during AST construction. For example, <code>a + b end * c</code> could be parsed as the green tree <code>(call-i a + b (error-t end * c))</code>, and turned into the AST <code>(call + a b)</code>.</li></ul><p>We want to encode both these cases in a way which is simplest for downstream tools to use. This is an open question, but for now we use <code>K&quot;error&quot;</code> as the kind, with the <code>TRIVIA_FLAG</code> set for unexpected syntax.</p><h1 id="Syntax-trees"><a class="docs-heading-anchor" href="#Syntax-trees">Syntax trees</a><a id="Syntax-trees-1"></a><a class="docs-heading-anchor-permalink" href="#Syntax-trees" title="Permalink"></a></h1><p>Julia&#39;s <code>Expr</code> abstract syntax tree can&#39;t store precise source locations or deal with syntax trivia like whitespace or comments. So we need some new tree types in <code>JuliaSyntax</code>.</p><p>JuliaSyntax currently deals in three types of trees:</p><ul><li><code>GreenNode</code> is a minimal <em>lossless syntax tree</em> where<ul><li>Nodes store a kind and length in bytes, but no text</li><li>Syntax trivia are included in the list of children</li><li>Children are strictly in source order</li></ul></li><li><code>SyntaxNode</code> is an <em>abstract syntax tree</em> which has<ul><li>An absolute position and pointer to the source text</li><li>Children strictly in source order</li><li>Leaf nodes store values, not text</li><li>Trivia are ignored, but there is a 1:1 mapping of non-trivia nodes to the associated <code>GreenTree</code> nodes.</li></ul></li><li><code>Expr</code> is used as a conversion target for compatibility</li></ul><h2 id="More-about-syntax-kinds"><a class="docs-heading-anchor" href="#More-about-syntax-kinds">More about syntax kinds</a><a id="More-about-syntax-kinds-1"></a><a class="docs-heading-anchor-permalink" href="#More-about-syntax-kinds" title="Permalink"></a></h2><p>We generally track the type of syntax nodes with a syntax &quot;kind&quot;, stored explicitly in each node an integer tag. This effectively makes the node type a <a href="https://blog.waleedkhan.name/union-vs-sum-types/">sum type</a> in the type system sense, but with the type tracked explicitly outside of Julia&#39;s type system.</p><p>Managing the type explicitly brings a few benefits:</p><ul><li>Code and data structures for manipulating syntax nodes is always concretely typed from the point of view of the compiler.</li><li>We control the data layout and can pack the kind into very few bits along with other flags bits, as desired.</li><li>Predicates such as <code>is_operator</code> can be extremely efficient, given that we know the meaning of the kind&#39;s bits.</li><li>The kind can be applied to several different tree data structures, or manipulated by itself.</li><li>Pattern matching code is efficient when the full set of kinds is closed and known during compilation.</li></ul><p>There&#39;s arguably a few downsides:</p><ul><li>Normal Julia dispatch can&#39;t express dispatch over syntax kind. Luckily, a pattern matching macro can provide a very elegant way of expressing such algorithms over a non-extensible set of kinds, so this is not a big problem.</li><li>Different node kinds could come with different data fields, but a syntax tree must have generic fields to cater for all kinds. (Consider as an analogy the normal Julia AST <code>QuoteNode</code> with a single field vs <code>Expr</code> with generic <code>head</code> and <code>args</code> fields.) This could be a disadvantage for code which processes one specific kind but for generic code processing many kinds having a generic but <em>concrete</em> data layout should be faster.</li></ul><h1 id="Differences-from-the-flisp-parser"><a class="docs-heading-anchor" href="#Differences-from-the-flisp-parser">Differences from the flisp parser</a><a id="Differences-from-the-flisp-parser-1"></a><a class="docs-heading-anchor-permalink" href="#Differences-from-the-flisp-parser" title="Permalink"></a></h1><p><em>See also the <a href="#comparisons-to-other-packages">§ Comparisons to other packages</a> section.</em></p><p>Practically the flisp parser is not quite a classic <a href="https://en.wikipedia.org/wiki/Recursive_descent_parser">recursive descent parser</a>, because it often looks back and modifies the output tree it has already produced. We&#39;ve tried to eliminate this pattern in favor of lookahead where possible because</p><ul><li>It works poorly when the parser is emitting a stream of node spans with strict source ordering constraints.</li><li>It&#39;s confusing to reason about this kind of code</li></ul><p>However, on occasion it seems to solve genuine ambiguities where Julia code can&#39;t be parsed top-down with finite lookahead. Eg for the <code>kw</code> vs <code>=</code> ambiguity within parentheses. In these cases we put up with using the functions <code>look_behind</code> and <code>reset_node!()</code>.</p><h2 id="Code-structure"><a class="docs-heading-anchor" href="#Code-structure">Code structure</a><a id="Code-structure-1"></a><a class="docs-heading-anchor-permalink" href="#Code-structure" title="Permalink"></a></h2><p>Large structural changes were generally avoided while porting. In particular, nearly all function names for parsing productions are the same with <code>-</code> replaced by <code>_</code> and predicates prefixed by <code>is_</code>.</p><p>Some notable differences:</p><ul><li><code>parse-arglist</code> and a parts of <code>parse-paren-</code> have been combined into a general function <code>parse_brackets</code>. This function deals with all the odd corner cases of how the AST is emitted when mixing <code>,</code> and <code>;</code> within parentheses. In particular regard to:<ul><li>Determining whether <code>;</code> are block syntax separators or keyword parameters</li><li>Determining whether to emit <code>parameter</code> sections based on context</li><li>Emitting key-value pairs either as <code>kw</code> or <code>=</code> depending on context</li></ul></li><li>The way that <code>parse-resword</code> is entered has been rearranged to avoid parsing reserved words with <code>parse-atom</code> inside <code>parse-unary-prefix</code>. Instead, we detect reserved words and enter <code>parse_resword</code> earlier.</li></ul><h2 id="Flisp-parser-bugs"><a class="docs-heading-anchor" href="#Flisp-parser-bugs">Flisp parser bugs</a><a id="Flisp-parser-bugs-1"></a><a class="docs-heading-anchor-permalink" href="#Flisp-parser-bugs" title="Permalink"></a></h2><p>Here&#39;s some behaviors which seem to be bugs. (Some of these we replicate in the name of compatibility, perhaps with a warning.)</p><ul><li>Macro module paths allow calls which gives weird stateful semantics!<pre><code class="language-julia hljs">b() = rand() &gt; 0.5 ? Base : Core
b().@info &quot;hi&quot;</code></pre></li><li>Misplaced <code>@</code> in macro module paths like <code>A.@B.x</code> is parsed as odd broken-looking AST like <code>(macrocall (. A (quote (. B @x))))</code>.  It should probably be rejected.</li><li>Operator prefix call syntax doesn&#39;t work in the cases like <code>+(a;b,c)</code> where keyword parameters are separated by commas. A tuple is produced instead.</li><li><code>const</code> and <code>global</code> allow chained assignment, but the right hand side is not constant. <code>a</code> const here but not <code>b</code>.<pre><code class="language-julia hljs">const a = b = 1</code></pre></li><li>Parsing the <code>ncat</code> array concatenation syntax within braces gives strange AST: <code>{a ;; b}</code> parses to <code>(bracescat 2 a b)</code> which is the same as <code>{2 ; a ; b}</code>, but should probably be <code>(bracescat (nrow 2 a b))</code> in analogy to how <code>{a b}</code> produces <code>(bracescat (row a b))</code>.</li><li><code>export a, \n $b</code> is rejected, but <code>export a, \n b</code> parses fine.</li><li>In try-catch-finally, the <code>finally</code> clause is allowed before the <code>catch</code>, but always executes afterward. (Presumably was this a mistake? It seems pretty awful!)</li><li>When parsing <code>&quot;[x \n\n ]&quot;</code> the flisp parser gets confused, but <code>&quot;[x \n ]&quot;</code> is correctly parsed as <code>Expr(:vect)</code> (maybe fixed in 1.7?)</li><li><code>f(x for x in in xs)</code> is accepted, and parsed very strangely.</li><li>Octal escape sequences saturate rather than being reported as errors. Eg, <code>&quot;\777&quot;</code> results in <code>&quot;\xff&quot;</code>.  This is inconsistent with <code>Base.parse(::Type{Int}, ...)</code></li><li>Leading dots in import paths with operator-named modules are parsed into dotted operators rather than a relative path. Ie, we have <code>import .⋆</code> parsing to <code>(import (. .⋆))</code> whereas it should be <code>(import (. . ⋆))</code> for consistency with the parsing of <code>import .A</code>.</li><li>Looking back on the output disregards grouping parentheses which can lead to odd results in some cases. For example, <code>f(((((x=1)))))</code> parses as a keyword call to function <code>f</code> with the keyword <code>x=1</code>, but arguably it should be an assignment.</li><li>Hexfloat literals can have a trailing <code>f</code> for example, <code>0x1p1f</code> but this doesn&#39;t do anything. In the <code>flisp</code> C code such cases are treated as Float32 literals and this was intentional https://github.com/JuliaLang/julia/pull/2925 but this has never been officially supported in Julia. It seems this bug arises from <code>(set! pred char-hex?)</code> in <code>parse-number</code> accepting hex exponent digits, all of which are detected as invalid except for a trailing <code>f</code> when processed by <code>isnumtok_base</code>.</li><li><code>begin</code> and <code>end</code> are not parsed as keywords when indexing. Typed comprehensions initially look the same, but can be distinguished from indexing once we handle a <code>for</code> token; it is safe to treat <code>begin</code> and <code>end</code> as keywords afterwards. The reference parser <em>only</em> handles this well when there&#39;s a newline before <code>for</code>:<pre><code class="language-julia hljs">Any[foo(i)
    for i in x if begin
        true
    end
]</code></pre>works, while<pre><code class="language-julia hljs">Any[foo(i) for i in x if begin
        true
    end
]</code></pre>does not. JuliaSyntax handles both cases.</li></ul><h2 id="Parsing-/-AST-oddities-and-warts"><a class="docs-heading-anchor" href="#Parsing-/-AST-oddities-and-warts">Parsing / AST oddities and warts</a><a id="Parsing-/-AST-oddities-and-warts-1"></a><a class="docs-heading-anchor-permalink" href="#Parsing-/-AST-oddities-and-warts" title="Permalink"></a></h2><h3 id="Questionable-allowed-forms"><a class="docs-heading-anchor" href="#Questionable-allowed-forms">Questionable allowed forms</a><a id="Questionable-allowed-forms-1"></a><a class="docs-heading-anchor-permalink" href="#Questionable-allowed-forms" title="Permalink"></a></h3><p>There&#39;s various allowed syntaxes which are fairly easily detected in the parser, but which will be rejected later during lowering. To allow building DSLs this is fine and good but some such allowed syntaxes don&#39;t seem very useful, even for DSLs:</p><ul><li><code>macro (x) end</code> is allowed but there are no anonymous macros.</li><li><code>abstract type A &lt; B end</code> and other subtype comparisons are allowed, but only <code>A &lt;: B</code> makes sense.</li><li><code>x where {S T}</code> produces <code>(where x (bracescat (row S T)))</code>. This seems pretty weird!</li><li><code>[x for outer x in xs]</code> parses, but <code>outer</code> makes no real sense in this context (and using this form is a lowering error)</li></ul><h3 id="kw-and-inconsistencies"><a class="docs-heading-anchor" href="#kw-and-inconsistencies"><code>kw</code> and <code>=</code> inconsistencies</a><a id="kw-and-inconsistencies-1"></a><a class="docs-heading-anchor-permalink" href="#kw-and-inconsistencies" title="Permalink"></a></h3><p>There&#39;s many apparent inconsistencies between how <code>kw</code> and <code>=</code> are used when parsing <code>key=val</code> pairs inside parentheses.</p><ul><li>Inconsistent parsing of tuple keyword args inside vs outside of dot calls<pre><code class="language-julia hljs">(a=1,)           # (tuple (= a 1))
f.(a=1)          # (tuple (kw a 1))</code></pre></li><li>Mixtures of <code>,</code> and <code>;</code> in calls give nested parameter AST which parses strangely, and is kind-of-horrible to use.<pre><code class="language-julia hljs"># (tuple (parameters (parameters e f) c d) a b)
(a,b; c,d; e,f)</code></pre></li><li>Long-form anonymous functions have argument lists which are parsed as tuples (or blocks!) rather than argument lists and this mess appears to be papered over as part of lowering. For example, in <code>function (a;b) end</code> the <code>(a;b)</code> is parsed as a block! This leads to more inconsistency in the use of <code>kw</code> for keywords.</li></ul><h3 id="Other-oddities"><a class="docs-heading-anchor" href="#Other-oddities">Other oddities</a><a id="Other-oddities-1"></a><a class="docs-heading-anchor-permalink" href="#Other-oddities" title="Permalink"></a></h3><ul><li><p>Operators with suffices don&#39;t seem to always be parsed consistently as the same operator without a suffix. Unclear whether this is by design or mistake. For example, <code>[x +y] ==&gt; (hcat x (+ y))</code>, but <code>[x +₁y] ==&gt; (hcat (call +₁ x y))</code></p></li><li><p><code>global const x=1</code> is normalized by the parser into <code>(const (global (= x 1)))</code>. I suppose this is somewhat useful for AST consumers, but reversing the source order is pretty weird and inconvenient when moving to a lossless parser.</p></li><li><p><code>let</code> bindings might be stored in a block, or they might not be, depending on special cases:</p><pre><code class="language-julia hljs"># Special cases not in a block
let x=1 ; end   # ==&gt;  (let (= x 1) (block))
let x::1 ; end  # ==&gt;  (let (:: x 1) (block))
let x ; end     # ==&gt;  (let x (block))

# In a block
let x=1,y=2 ; end  # ==&gt;  (let (block (= x 1) (= y 2) (block)))
let x+=1 ; end     # ==&gt;  (let (block (+= x 1)) (block))</code></pre></li><li><p>The <code>elseif</code> condition is always in a block but not the <code>if</code> condition. Presumably because of the need to add a line number node in the flisp parser <code>if a xx elseif b yy end   ==&gt;  (if a (block xx) (elseif (block b) (block yy)))</code></p></li><li><p>Spaces are allowed between import dots — <code>import . .A</code> is allowed, and parsed the same as <code>import ..A</code></p></li><li><p><code>import A..</code> produces <code>(import (. A .))</code> which is arguably nonsensical, as <code>.</code> can&#39;t be a normal identifier.</p></li><li><p>The raw string escaping rules are <em>super</em> confusing for backslashes near the end of the string: <code>raw&quot;\\\\ &quot;</code> contains four backslashes, whereas <code>raw&quot;\\\\&quot;</code> contains only two. However this was an intentional feature to allow all strings to be represented and it&#39;s unclear whether the situation can be improved.</p></li><li><p>In braces after macrocall, <code>@S{a b}</code> is invalid but both <code>@S{a,b}</code> and <code>@S {a b}</code> parse. Conversely, <code>@S[a b]</code> parses.</p></li><li><p>Macro names and invocations are post-processed from the output of <code>parse-atom</code> / <code>parse-call</code>, which leads to some surprising and questionable constructs which &quot;work&quot;:</p><ul><li>Absurdities like <code>@(((((a))))) x ==&gt; (macrocall @a x)</code></li><li>Infix macros!? <code>@(x + y)  ==&gt;  (macrocall @+ x y)</code> (ok, kinda cute and has some weird logic to it... but what?)</li><li>Similarly additional parentheses are allowed <code>@(f(x)) ==&gt; (macrocall @f x)</code></li></ul></li><li><p>Allowing <code>@</code> first in macro module paths (eg <code>@A.B.x</code> instead of <code>A.B.@x</code>) seems like unnecessary variation in syntax. It makes parsing valid macro module paths more complex and leads to oddities like <code>@$.x y ==&gt; (macrocall ($ (quote x)) y</code> where the <code>$</code> is first parsed as a macro name, but turns out to be the module name after the <code>.</code> is parsed. But <code>$</code> can never be a valid module name in normal Julia code so this makes no sense.</p></li><li><p>Triple quoted <code>var&quot;&quot;&quot;##&quot;&quot;&quot;</code> identifiers are allowed. But it&#39;s not clear these are required or desired given that they come with the complex triple-quoted string deindentation rules.</p></li><li><p>Deindentation of triple quoted strings with mismatched whitespace is weird when there&#39;s nothing but whitespace. For example, we have <code>&quot;\&quot;\&quot;\&quot;\n  \n \n  \&quot;\&quot;\&quot;&quot; ==&gt; &quot;\n \n&quot;</code> so the middle line of whitespace here isn&#39;t dedented but the other two longer lines are?? Here it seems more consistent that either (a) the middle line should be deindented completely, or (b) all lines should be dedented only one character, as that&#39;s the matching prefix.</p></li><li><p>Parsing of anonymous function arguments is somewhat inconsistent. <code>function (xs...) \n body end</code> parses the argument list as <code>(... xs)</code>, whereas <code>function (x) \n body end</code> parses the argument list as <code>(tuple x)</code>.</p></li><li><p>The difference between multidimensional vs flattened iterators is subtle, and perhaps too syntactically permissive.  For example,</p><ul><li><code>[(x,y) for x * in 1:10, y in 1:10]</code> is a multidimensional iterator</li><li><code>[(x,y) for x * in 1:10 for y in 1:10]</code> is a flattened iterator</li><li><code>[(x,y) for x in 1:10, y in 1:10 if y &lt; x]</code> is a flattened iterator</li></ul><p>It&#39;s this last case which seems problematic (why not <em>require</em> the second form as a more explicit way to indicate flattening?). It&#39;s not even pretty printed correctly:</p><pre><code class="language-julia-repl hljs">julia&gt; :([(x,y) for x in 1:10, y in 1:10 if y &lt; x])
:([(x, y) for $(Expr(:filter, :(y &lt; x), :(x = 1:10), :(y = 1:10)))])</code></pre></li><li><p>The character <code>&#39;</code> may be written without escaping as <code>&#39;&#39;&#39;</code> rather than requiring the form <code>&#39;\&#39;&#39;</code>.</p></li></ul><h1 id="Comparisons-to-other-packages"><a class="docs-heading-anchor" href="#Comparisons-to-other-packages">Comparisons to other packages</a><a id="Comparisons-to-other-packages-1"></a><a class="docs-heading-anchor-permalink" href="#Comparisons-to-other-packages" title="Permalink"></a></h1><h3 id="Official-Julia-compiler"><a class="docs-heading-anchor" href="#Official-Julia-compiler">Official Julia compiler</a><a id="Official-Julia-compiler-1"></a><a class="docs-heading-anchor-permalink" href="#Official-Julia-compiler" title="Permalink"></a></h3><p><em>See also the <a href="#differences-from-the-flisp-parser">§ Differences from the flisp parser</a> section.</em></p><p>The official Julia compiler frontend lives in the Julia source tree. It&#39;s mostly contained in just a few files:</p><ul><li>The parser in <a href="https://github.com/JuliaLang/julia/blob/9c4b75d7f63d01d12b67aaf7ce8bb4a078825b52/src/julia-parser.scm">src/julia-parser.scm</a></li><li>Macro expansion in <a href="https://github.com/JuliaLang/julia/blob/9c4b75d7f63d01d12b67aaf7ce8bb4a078825b52/src/ast.c">src/ast.c</a> and <a href="https://github.com/JuliaLang/julia/blob/9c4b75d7f63d01d12b67aaf7ce8bb4a078825b52/src/macroexpand.scm">src/macroexpand.scm</a></li><li>Syntax lowering in <a href="https://github.com/JuliaLang/julia/blob/9c4b75d7f63d01d12b67aaf7ce8bb4a078825b52/src/julia-syntax.scm">src/julia-syntax.scm</a></li><li>The flisp runtime and C extensions for Julia in <a href="https://github.com/JuliaLang/julia/tree/master/src/flisp">src/flisp</a></li><li>Supporting utility functions in a few other <code>.scm</code> and <code>.c</code> files.</li></ul><p>There&#39;s two issues with the official reference frontend which suggest a rewrite.</p><p>First, there&#39;s no support for precise source locations and the existing data structures (bare flisp lists) can&#39;t easily be extended to add these. Fixing this would require changes to nearly all of the code.</p><p>Second, it&#39;s written in flisp: an aestheically pleasing, minimal but obscure implementation of Scheme. Learning Scheme is actually a good way to appreciate some of Julia&#39;s design inspiration, but it&#39;s quite a barrier for developers of Julia language tooling. (Flisp has no user-level documentation but non-schemers can refer to the <a href="https://docs.racket-lang.org">Racket documentation</a> which is quite compatible for basic things.) In addition to the social factors, having the embedded flisp interpreter and runtime with its own separate data structures and FFI is complex and inefficient.</p><h3 id="JuliaParser.jl"><a class="docs-heading-anchor" href="#JuliaParser.jl">JuliaParser.jl</a><a id="JuliaParser.jl-1"></a><a class="docs-heading-anchor-permalink" href="#JuliaParser.jl" title="Permalink"></a></h3><p><a href="https://github.com/JuliaLang/JuliaParser.jl">JuliaParser.jl</a> was a direct port of Julia&#39;s flisp reference parser, but was abandoned around Julia 0.5 or so. Furthermore, it doesn&#39;t support lossless parsing, and adding that feature would amount to a full rewrite. Given its divergence with the flisp reference parser since Julia-0.5, it seemed better just to start anew from the reference parser instead.</p><h3 id="Tokenize.jl"><a class="docs-heading-anchor" href="#Tokenize.jl">Tokenize.jl</a><a id="Tokenize.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Tokenize.jl" title="Permalink"></a></h3><p><a href="https://github.com/JuliaLang/Tokenize.jl">Tokenize.jl</a> is a fast lexer for Julia code. The code from Tokenize has been imported and used in JuliaSyntax, with some major modifications as discussed in the <a href="#lexing">lexer implementation</a> section.</p><h3 id="CSTParser.jl"><a class="docs-heading-anchor" href="#CSTParser.jl">CSTParser.jl</a><a id="CSTParser.jl-1"></a><a class="docs-heading-anchor-permalink" href="#CSTParser.jl" title="Permalink"></a></h3><p><a href="https://github.com/julia-vscode/CSTParser.jl">CSTParser.jl</a> is a (<a href="https://github.com/domluna/JuliaFormatter.jl/issues/52#issuecomment-529945126">mostly?</a>) lossless parser with goals quite similar to JuliaParser. It is used extensively in the VSCode / LanguageServer / JuliaFormatter ecosystem. CSTParser is very useful, but I do find the implementation hard to understand, and I wanted to try a fresh approach with a focus on:</p><ul><li>&quot;Production readiness&quot;: Good docs, tests, diagnostics and maximum similarity with the flisp parser, with the goal of getting the new parser into <code>Core</code>.</li><li>Learning from the latest ideas about composable parsing and data structures from outside Julia. In particular the implementation of <code>rust-analyzer</code> is very clean, well documented, and was a great source of inspiration.</li><li>Composability of tree data structures — I feel like the trees should be layered somehow with a really lightweight <a href="#raw-syntax-tree--green-tree">green tree</a> at the most basic level, similar to Roslyn or rust-analyzer. In comparison, CSTParser uses a more heavyweight non-layered data structure. Alternatively or additionally, have a common tree API with many concrete task-specific implementations.</li></ul><p>A big benefit of the JuliaSyntax parser is that it separates the parser code from the tree data structures entirely, which should give a lot of flexibility in experimenting with various tree representations.</p><p>I also want JuliaSyntax to tackle macro expansion and other lowering steps, and provide APIs for this which can be used by both the core language and the editor tooling.</p><h3 id="tree-sitter-julia"><a class="docs-heading-anchor" href="#tree-sitter-julia">tree-sitter-julia</a><a id="tree-sitter-julia-1"></a><a class="docs-heading-anchor-permalink" href="#tree-sitter-julia" title="Permalink"></a></h3><p>Using a modern production-ready parser generator like <code>tree-sitter</code> is an interesting option and some progress has already been made in <a href="https://github.com/tree-sitter/tree-sitter-julia">tree-sitter-julia</a>. But I feel like the grammars for parser generators are only marginally more expressive than writing the parser by hand, after accounting for the effort spent on the weird edge cases of a real language and writing the parser&#39;s tests and &quot;supporting code&quot;.</p><p>On the other hand, a hand-written parser is completely flexible and can be mutually understood with the reference implementation, so I chose that approach for JuliaSyntax.</p><h1 id="Resources"><a class="docs-heading-anchor" href="#Resources">Resources</a><a id="Resources-1"></a><a class="docs-heading-anchor-permalink" href="#Resources" title="Permalink"></a></h1><h2 id="Julia-issues"><a class="docs-heading-anchor" href="#Julia-issues">Julia issues</a><a id="Julia-issues-1"></a><a class="docs-heading-anchor-permalink" href="#Julia-issues" title="Permalink"></a></h2><p>Here&#39;s a few links to relevant Julia issues.</p><h4 id="Macro-expansion"><a class="docs-heading-anchor" href="#Macro-expansion">Macro expansion</a><a id="Macro-expansion-1"></a><a class="docs-heading-anchor-permalink" href="#Macro-expansion" title="Permalink"></a></h4><ul><li>Automatic hygiene for macros https://github.com/JuliaLang/julia/pull/6910 — would be interesting to implement this in a new frontend.</li></ul><h4 id="Lowering"><a class="docs-heading-anchor" href="#Lowering">Lowering</a><a id="Lowering-1"></a><a class="docs-heading-anchor-permalink" href="#Lowering" title="Permalink"></a></h4><ul><li>A partial implementation of lowering in Julia https://github.com/JuliaLang/julia/pull/32201 — some of this should be ported. (Last commit at https://github.com/JuliaLang/julia/tree/df61138fcf97d03dcbbba10e962571af9700db56/ )</li><li>The closure capture problem https://github.com/JuliaLang/julia/issues/15276 — would be interesting to see whether we can tackle some of the harder cases in a new implementation.</li></ul><h2 id="C#-Roslyn"><a class="docs-heading-anchor" href="#C#-Roslyn">C# Roslyn</a><a id="C#-Roslyn-1"></a><a class="docs-heading-anchor-permalink" href="#C#-Roslyn" title="Permalink"></a></h2><p><a href="https://ericlippert.com/2012/06/08/red-green-trees/">Persistence, façades and Roslyn’s red-green trees</a></p><ul><li><a href="https://github.com/KirillOsenkov/Bliki/wiki/Roslyn-Immutable-Trees">Roslyn optimization overview</a></li><li><a href="https://johtela.github.io/LiterateCS/LiterateCS/BlockBuilder.html">Literate C# Usage Example</a></li></ul><h2 id="Rust-analyzer"><a class="docs-heading-anchor" href="#Rust-analyzer">Rust-analyzer</a><a id="Rust-analyzer-1"></a><a class="docs-heading-anchor-permalink" href="#Rust-analyzer" title="Permalink"></a></h2><p><code>rust-analyzer</code> seems to be very close to what I&#39;m building here, and has come to the same conclusions on green tree layout with explicit trivia nodes.  Their document on internals <a href="https://github.com/rust-analyzer/rust-analyzer/blob/master/docs/dev/syntax.md">here</a> is great. Points of note:</p><ul><li>They have <em>three</em> trees!<ol><li>Green trees exactly like mine (pretty much all the same design decisions, including trivia storage). Though note that the team are still <a href="https://github.com/rust-analyzer/rust-analyzer/issues/6584">toying with</a> the idea of using the Roslyn model of trivia.</li><li>Untyped red syntax trees somewhat like mine, but much more minimal. For example, these don&#39;t attempt to reorder children.</li><li>A typed AST layer with a type for each expression head. The AST searches for children by dynamically traversing the child list each time, rather than having a single canonical ordering or remembering the placement of children which the parser knew.</li></ol></li><li>&quot;Parser does not see whitespace nodes. Instead, they are attached to the tree in the TreeSink layer.&quot; This may be relevant to us - it&#39;s a pain to attach whitespace to otherwise significant tokens, and inefficient to allocate and pass around a dynamic list of whitespace trivia.</li><li>&quot;In practice, incremental reparsing doesn&#39;t actually matter much for IDE use-cases, parsing from scratch seems to be fast enough.&quot; (I wonder why they&#39;ve implemented incremental parsing then?)</li><li>There&#39;s various comments about macros... Rust macro expansion seems quite different from Julia (it appears it may be interleaved with parsing??)</li></ul><p>In general I think it&#39;s unclear whether we want typed ASTs in Julia and we particularly need to deal with the fact that <code>Expr</code> is the existing public interface. Could we have <code>Expr2</code> wrap <code>SyntaxNode</code>?</p><ul><li>A related very useful set of blog posts which discuss using the rust syntax tree library (rowan) for representing of a non-rust toy language is here https://dev.to/cad97/lossless-syntax-trees-280c</li></ul><p>Not all the design decisions in <code>rust-analyzer</code> are finalized but the <a href="https://github.com/rust-analyzer/rust-analyzer/blob/master/docs/dev/architecture.md">architecture document</a> is a fantastic source of design inspiration.</p><p>Highlights:</p><ul><li>&quot;The parser is independent of the particular tree structure and particular representation of the tokens. It transforms one flat stream of events into another flat stream of events.&quot;  This seems great, let&#39;s adopt it!</li><li>TODO</li></ul><h2 id="RSLint"><a class="docs-heading-anchor" href="#RSLint">RSLint</a><a id="RSLint-1"></a><a class="docs-heading-anchor-permalink" href="#RSLint" title="Permalink"></a></h2><p><a href="https://rslint.org/dev">RSLint</a> is a linter for javascript, built in Rust. It uses the same parsing infrastructure and green tree libraries <code>rust-analyzer</code>. There&#39;s an excellent and friendly high level overview of how all this works in the rslint <a href="https://rslint.org/dev/parsing.html">parsing devdocs</a>.</p><p>Points of note:</p><ul><li><p>Backtracking and restarting the parser on error is actually quite simple in the architecture we (mostly) share with <code>rust-analyzer</code>:</p><blockquote><p>... events allow us to cheaply backtrack the parser by simply draining the events and resetting the token source cursor back to some place.</p></blockquote></li><li><p>The section on <a href="https://rslint.org/dev/parsing.html#error-recovery">error recovery</a> is interesting; they talk about various error recovery strategies.</p></li></ul><h2 id="Diagnostics"><a class="docs-heading-anchor" href="#Diagnostics">Diagnostics</a><a id="Diagnostics-1"></a><a class="docs-heading-anchor-permalink" href="#Diagnostics" title="Permalink"></a></h2><p>The paper <a href="https://wg21.tartanllama.xyz/P2429%20-%20Concepts%20Error%20Messages%20for%20Humans.pdf">P2429 - Concepts Error Messages for Humans</a> is C++ centric, but has a nice review of quality error reporting in various compilers including Elm, ReasonML, Flow, D and Rust.</p><p>Some Rust-specific resources:</p><ul><li><a href="https://doc.rust-lang.org/stable/nightly-rustc/rustc_errors/struct.Diagnostic.html">rustc_errors::Diagnostic</a></li><li>The source of the Rust compiler&#39;s diagnostics system:<ul><li>The <a href="https://github.com/rust-lang/rust/blob/0b6f079e4987ded15c13a15b734e7cfb8176839f/compiler/rustc_builtin_macros/src/format.rs"><code>println!</code> macro</a> shows how these can be emitted from macros</li><li>The parser&#39;s <a href="https://github.com/rust-lang/rust/blob/0b6f079e4987ded15c13a15b734e7cfb8176839f/compiler/rustc_parse/src/parser/diagnostics.rs">diagnostics.rs</a></li></ul></li></ul><h2 id="General-resources-about-parsing"><a class="docs-heading-anchor" href="#General-resources-about-parsing">General resources about parsing</a><a id="General-resources-about-parsing-1"></a><a class="docs-heading-anchor-permalink" href="#General-resources-about-parsing" title="Permalink"></a></h2><ul><li><p><a href="https://matklad.github.io/2018/06/06/modern-parser-generator.html">Modern parser generator</a> has a lot of practical notes on writing parsers. Highlights:</p><ul><li>Encourages writing tests for handwritten parsers as inline comments</li><li>Mentions Pratt parsers for simple operator precedence parsing. Good articles:<ul><li><a href="https://matklad.github.io/2020/04/13/simple-but-powerful-pratt-parsing.html">From Aleksey Kladov (matklad - the main rust-analyzer author, etc)</a></li><li><a href="http://journal.stuffwithstuff.com/2011/03/19/pratt-parsers-expression-parsing-made-easy/">From Bob Nystrom (munificent - one of the Dart devs, etc</a></li></ul></li><li>Some discussion of error recovery</li></ul></li><li><p>Some notes about stateful lexers for parsing shell-like string interpolations: http://www.oilshell.org/blog/2017/12/17.html</p></li></ul><h1 id="Design-notes"><a class="docs-heading-anchor" href="#Design-notes">Design notes</a><a id="Design-notes-1"></a><a class="docs-heading-anchor-permalink" href="#Design-notes" title="Permalink"></a></h1><p>The following are some fairly disorganized design notes covering a mixture of things which have already been done and musings about further work.</p><h2 id="Prototyping-approach"><a class="docs-heading-anchor" href="#Prototyping-approach">Prototyping approach</a><a id="Prototyping-approach-1"></a><a class="docs-heading-anchor-permalink" href="#Prototyping-approach" title="Permalink"></a></h2><p>The tree datastructure design here is tricky:</p><ol><li>The symbolic part of compilation (the compiler frontend) incrementally abstracts and transforms the source text, but errors along the way should refer back to the source.</li></ol><ul><li>The tree must be a lossless representation of the source text</li><li>Some aspects of the source text (comments, most whitespace) are irrelevant to parsing.</li><li>More aspects of the source text are irrelevant after we have an abstract syntax tree of the surface syntax. Some good examples here are the parentheses in <code>2*(x + y)</code> and the explicit vs implicit multiplication symbol in <code>2*x</code> vs <code>2x</code>.</li></ul><ol><li>There&#39;s various type of <em>analyses</em></li></ol><ul><li>There&#39;s many useful ways to augment a syntax tree depending on use case.</li><li>Analysis algorithms should be able to act on any tree type, ignoring but carrying augmentations which they don&#39;t know about.</li></ul><p>Having so many use cases suggests it might be best to have several different tree types with a common interface rather than one main abstract syntax tree type. But it seems useful to figure this out by prototyping several important work flows:</p><ul><li>Syntax transformations<ul><li>Choose some macros to implement. This is a basic test of mixing source trees from different files while preserving precise source locations. (Done in &lt;test/syntax_interpolation.jl&gt;.)</li></ul></li><li>Formatting<ul><li>Re-indent a file. This tests the handling of syntax trivia.</li></ul></li><li>Refactoring<ul><li>A pass to rename local variables. This tests how information from further down the compilation pipeline can be attached to the syntax tree and used to modify the source code.</li></ul></li><li>Precise error reporting in lowering<ul><li>Syntax desugaring <code>[a, b] = (c, d)</code> should report &quot;invalid assignment location <code>[a, b]</code>&quot;. But at a precise source location.</li><li>Try something several layers deeper inside lowering? For example &quot;macro definition not allowed inside a local scope&quot;</li></ul></li><li>Incremental reparsing<ul><li>Reparse a source file, given a byte range replacement</li></ul></li></ul><h2 id="Tree-design"><a class="docs-heading-anchor" href="#Tree-design">Tree design</a><a id="Tree-design-1"></a><a class="docs-heading-anchor-permalink" href="#Tree-design" title="Permalink"></a></h2><h3 id="Raw-syntax-tree-/-Green-tree"><a class="docs-heading-anchor" href="#Raw-syntax-tree-/-Green-tree">Raw syntax tree / Green tree</a><a id="Raw-syntax-tree-/-Green-tree-1"></a><a class="docs-heading-anchor-permalink" href="#Raw-syntax-tree-/-Green-tree" title="Permalink"></a></h3><p>Raw syntax tree (or <a href="https://ericlippert.com/2012/06/08/red-green-trees/">&quot;Green tree&quot;</a> in the terminology from Roslyn)</p><p>We want GreenNode to be</p><ul><li><em>structurally minimal</em> — For efficiency and generality</li><li><em>immutable</em>            — For efficiency (&amp; thread safety)</li><li><em>complete</em>             — To preserve parser knowledge</li><li><em>token agnostic</em>       — To allow use with any source language</li></ul><p>The simplest idea possible is to have:</p><ul><li>Leaf nodes are a single token</li><li>Children are in source order</li></ul><p>Call represents a challenge for the AST vs Green tree in terms of node placement / iteration for infix operators vs normal prefix function calls.</p><ul><li>The normal problem of <code>a + 1</code> vs <code>+(a, 1)</code></li><li>Or worse, <code>a + 1 + 2</code> vs <code>+(a, 1, 2)</code></li></ul><p>Clearly in the AST&#39;s <em>interface</em> we need to abstract over this placement. For example with something like the normal Julia AST&#39;s iteration order.</p><h3 id="Abstract-syntax-tree"><a class="docs-heading-anchor" href="#Abstract-syntax-tree">Abstract syntax tree</a><a id="Abstract-syntax-tree-1"></a><a class="docs-heading-anchor-permalink" href="#Abstract-syntax-tree" title="Permalink"></a></h3><p>By pointing to green tree nodes, AST nodes become traceable back to the original source.</p><p>Unlike most languages, designing a new AST is tricky because the existing <code>Expr</code> is a very public API used in every macro expansion. User-defined macro expansions interpose between the source text and lowering, and using <code>Expr</code> looses source information in many ways.</p><p>There seems to be a few ways forward:</p><ul><li>Maybe we can give <code>Expr</code> some new semi-hidden fields to point back to the green tree nodes that the <code>Expr</code> or its <code>args</code> list came from?</li><li>We can use the existing <code>Expr</code> during macro expansion and try to recover source information after macro expansion using heuristics. Likely the presence of correct hygiene can help with this.</li><li>Introducing a new AST would be possible if it were opt-in for some hypothetical &quot;new-style macros&quot; only. Fixing hygiene should go along with this. Design challenge: How do we make manipulating expressions reasonable when literals need to carry source location?</li></ul><p>One option which may help bridge between locationless ASTs and something new may be to have wrappers for the small number of literal types we need to cover. For example:</p><pre><code class="language-julia hljs">SourceSymbol &lt;: AbstractSymbol
SourceInt    &lt;: Integer
SourceString &lt;: AbstractString</code></pre><p>Having source location attached to symbols would potentially solve most of the hygiene problem. There&#39;s still the problem of macro helper functions which use symbol literals; we can&#39;t very well be changing the meaning of <code>:x</code>! Perhaps the trick there is to try capturing the current module at the location of the interpolation syntax. Eg, if you do <code>:(y + $x)</code>, lowering expands this to <code>Core._expr(:call, :+, :y, x)</code>, but it could expand it to something like <code>Core._expr(:call, :+, :y, _add_source_symbol(_module_we_are_lowering_into, x))</code>?</p><h2 id="Parsing"><a class="docs-heading-anchor" href="#Parsing">Parsing</a><a id="Parsing-1"></a><a class="docs-heading-anchor-permalink" href="#Parsing" title="Permalink"></a></h2><h3 id="Error-recovery-2"><a class="docs-heading-anchor" href="#Error-recovery-2">Error recovery</a><a class="docs-heading-anchor-permalink" href="#Error-recovery-2" title="Permalink"></a></h3><p>Some disorganized musings about error recovery</p><p>Different types of errors seem to occur...</p><ul><li>Disallowed syntax (such as lack of spaces in conditional expressions) where we can reasonably just continue parsing and emit the node with an error flag which is otherwise fully formed. In some cases like parsing infix expressions with a missing tail, emitting a zero width error token can lead to a fully formed parse tree without the productions up the stack needing to participate in recovery.</li><li>A token which is disallowed in current context. Eg, <code>=</code> in parse_atom, or a closing token inside an infix expression. Here we can emit a <code>K&quot;error&quot;</code>, but we can&#39;t descend further into the parse tree; we must pop several recursive frames off. Seems tricky!</li></ul><p>A typical structure is as follows:</p><pre><code class="language-julia hljs">function parse_foo(ps)
    mark = position(ps)
    parse_bar(ps)  # What if this fails?
    if peek(ps) == K&quot;some-token&quot;
        bump(ps)
        parse_baz(ps)  # What if this fails?
        emit(ps, mark, K&quot;foo&quot;)
    end
end</code></pre><p>Emitting plain error tokens are good in unfinished infix expressions:</p><pre><code class="language-julia hljs">begin
    a = x +
end</code></pre><p>The &quot;missing end&quot; problem is tricky, as the intermediate syntax is valid; the problem is often only obvious until we get to EOF.</p><p>Missing end</p><pre><code class="language-julia hljs">function f()
    begin
        a = 10
end

# &lt;-- Indentation would be wrong if g() was an inner function of f.
function g()
end</code></pre><p>It seems like ideal error recovery would need to backtrack in this case. For example:</p><ul><li>Pop back to the frame which was parsing <code>f()</code></li><li>Backtrack through the parse events until we find a function with indentation mismatched to the nesting of the parent.</li><li>Reset ParseStream to a parsing checkpoint before <code>g()</code> was called</li><li>Emit error and exit the function parsing <code>f()</code></li><li>Restart parsing</li><li>Somehow make sure all of this can&#39;t result in infinite recursion 😅</li></ul><p>Missing commas or closing brackets in nested structures also present the existing parser with a problem.</p><pre><code class="language-julia hljs">f(a,
  g(b,
    c    # -- missing comma?
    d),
  e)</code></pre><p>Again the local indentation might tell a story</p><pre><code class="language-julia hljs">f(a,
  g(b,
    c    # -- missing closing `)` ?
  d)</code></pre><p>But not always!</p><pre><code class="language-julia hljs">f(a,
  g(b,
    c    # -- missing closing `,` ?
  d))</code></pre><p>Another particularly difficult problem for diagnostics in the current system is broken parentheses or double quotes in string interpolations, especially when nested.</p><h1 id="Fun-research-questions"><a class="docs-heading-anchor" href="#Fun-research-questions">Fun research questions</a><a id="Fun-research-questions-1"></a><a class="docs-heading-anchor-permalink" href="#Fun-research-questions" title="Permalink"></a></h1><h3 id="Parser-Recovery"><a class="docs-heading-anchor" href="#Parser-Recovery">Parser Recovery</a><a id="Parser-Recovery-1"></a><a class="docs-heading-anchor-permalink" href="#Parser-Recovery" title="Permalink"></a></h3><p>Can we learn fast and reasonably accurate recovery heuristics for when the parser encounters broken syntax, rather than hand-coding these? How would we set the parser up so that training works and injecting the model is nonintrusive? If the model is embedded in and works together with the parser, can it be made compact enough that training is fast and the model itself is tiny?</p><h3 id="Formatting"><a class="docs-heading-anchor" href="#Formatting">Formatting</a><a id="Formatting-1"></a><a class="docs-heading-anchor-permalink" href="#Formatting" title="Permalink"></a></h3><p>Given source and syntax tree, can we regress/learn a generative model of indentation from the syntax tree?  Source formatting involves a big pile of heuristics to get something which &quot;looks nice&quot;... and ML systems have become very good at heuristics. Also, we&#39;ve got huge piles of training data — just choose some high quality, tastefully hand-formatted libraries.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../api/">« API Reference</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Tuesday 20 August 2024 04:52">Tuesday 20 August 2024</span>. Using Julia version 1.10.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
